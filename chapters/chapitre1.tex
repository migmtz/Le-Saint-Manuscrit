\leadchapter{
  
}

\chapter[][]{An introduction to Hawkes processes study}\label{chapter:background}

\section{Introduction}

Point processes are a fundamental concept in stochastic modelling, providing a framework for analysing events that occur randomly over time. 
Traditionally, a temporal point process is presented through the concept of an ordered collection of random variables in the real line, each one representing the occurrence of an event.
A standard approach to study point processes is by defining random measures, which are random variables with realisations on the space of boundedly finite measures.
In particular, this framework gives access to many results from set theory and measure theory as largely shown in the literature \parencite{Cox1980, Baddeley2006, DaleyV2, Baccelli2020}.

In this chapter, we present a succinct introduction to these concepts in order to present the submodel of past-dependent point processes: the Hawkes model \parencite{Hawkes1971}.
Our goal here is twofold: the first one is to introduce numerous notations and definitions that are used throughout this manuscript, serving as a general reference for further chapters. The second is to present a short review of the original self-exciting Hawkes processes and some numerical procedures from the literature.

We introduce the concept of temporal point processes through random measure theory in Section~\ref{sec:chap1_random_measures} with a particular interest on the concept of conditional intensity functions. 
With this background, we formally introduce the univariate self-exciting Hawkes processes in Section~\ref{sec:chap1_hawkes_process} with the two classical extensions to multivariate and  non-linear settings, the latter being often used to model inhibition effects.
We follow up with a general presentation of some classic inference methods in Section~\ref{sec:chap1_inference} and we conclude with Section~\ref{sec:chap1_simulation} by presenting two methods of simulation that are commonly used in the context of Hawkes processes.


\section{Random measures and point processes}\label{sec:chap1_random_measures}

\subsection{Random measures}

Let $\mathcal{X} \subseteq \RR$ denote either the real half-line $\RR_{\geq 0}$ or the real line $\RR$ and $\mathcal{B}_{\mathcal{X}}$ be the Borel $\sigma$-algebra of $\mathcal{X}$.

\begin{definition}
    A measure $\nu$ on $\mathcal{X}$ is said to be \emph{boundedly finite} if for any bounded $B\in\mathcal{B}_{\mathcal{X}}$, $\nu(B) < +\infty$ and we define $\mathcal{M}_{\mathcal{X}}$ as the set of boundedly finite measures on $\mathcal{X}$.
\end{definition}

For $\mathcal{M}_{\mathcal{X}}$, we may obtain Borel $\sigma$-algebras generated by the mappings $\nu \mapsto \nu(B)$, for all $B\in\mathcal{B}_{\mathcal{X}}$, that we note $\mathcal{B}(\mathcal{M}_{\mathcal{X}})$.

Let $(\Omega, \mathcal{F}, \PP)$ be a probability space.

\begin{definition}[Random measure]
    A \emph{random measure} $\xi$ on $\mathcal{X}$ is a measurable mapping from $\Omega$ into $\mathcal{M}_{\mathcal{X}}$.
    The distribution of a random measure $\xi$ is the probability measure induced by the probability measure $\PP$.
\end{definition}

%In this sense, $\xi$ is a random variable on the measurable set $\mathcal{M}_{\mathcal{X}}$ whose realisation is a deterministic measure on $\mathcal{X}$.
An equivalent definition of a random measure is obtained through the following result.

\begin{proposition}{\parencite[Proposition 1.1.7]{Baccelli2020}}\label{prop:chap1_random_measure_variable}

    For a mapping $\xi:(\Omega, \mathcal{F}) \to (\mathcal{M}_{\mathcal{X}}, \mathcal{B}(\mathcal{M}_{\mathcal{X}}))$, we define for any $B\in\mathcal{B}_{\mathcal{X}}$ the mapping $\xi(B):(\Omega, \mathcal{F}) \to (\mathcal{X}, \mathcal{B}_{\mathcal{X}})$ as:
    \[\left(\xi(B)\right)(\omega) = (\xi(\omega))(B)\,.\]

    Then, $\xi$ is a random measure if and only if, for all $B\in\mathcal{B}_{\mathcal{X}}$, $\xi(B)$ is measurable.
\end{proposition}
With this result, it means that we can work with a random measure $\xi$ in two ways:
\begin{itemize}
    \item For any $\omega\in\Omega$, a realisation $\xi(\omega)$ is a measure on $\mathcal{X}$.
    \item For any $B\in\mathcal{B}_{\mathcal{X}}$, $\xi(B)$ is a random variable on $\mathcal{X}$. Furthermore, $\{\xi(B)\}_{B\in\mathcal{B}_{\mathcal{X}}}$ is a stochastic process.
\end{itemize}
In practice, as with other random variables we tend to omit the term $\omega$ when working with random measures and using $\xi$ either as a measure or random variable is to be understood by the context.
Another direct result from Proposition~\ref{prop:chap1_random_measure_variable} is that, for any finite sequence $(B_k)_{k=1:K}$ of Borel sets, we can define the random vector:
\[(\xi(B_1), \ldots, \xi(B_K))\,.\]
It turns out that a characterisation of any random measure is given by the distribution of all of these vectors.

\begin{proposition}{\parencite[Corollary 9.2.IV]{DaleyV2}}

    Let $\xi$ be a random measure on $\mathcal{X}$. 
    The finite-dimensional distributions of $\xi$ are the probability distribution of the vectors $(\xi(B_1), \ldots, \xi(B_K))$ for all integers $K\geq 1$ and all sequences of Borel sets $(B_k)_{k=1:K}$.

    The distribution of $\xi$ is fully given by its finite-dimensional distributions.
\end{proposition}
With this result, a way of defining any random measure is by defining its finite-dimensional distributions.
However, not any set of finite-dimensional distributions corresponds to those of a random measure, but a set of necessary and sufficient conditions is proposed in \textcite[Conditions 9.2.V-VI]{DaleyV2}, namely Kolmogorov extension theorem conditions and additivity and continuity conditions.
Finally, let us introduce the notion of stationarity. 
For any $B\in\mathcal{B}_{\mathcal{X}}$, for any $x\in\mathcal{X}$, we define $B+x$ as the set:
\[B+x = \{b + x \mid b\in B\}\,.\]

\begin{definition}
    A random measure $\xi$ is said to be \emph{stationary} if 
    for any $B\in\mathcal{B}_{\mathcal{X}}$ and for any $x\in\mathcal{X}$, $N(B)$ and $N(B+x)$ follow the same distribution.
\end{definition}

\subsection{Point processes}

Let us now turn to the study of point processes. For this, we need the definition of a counting measure.

\begin{definition}
    A measure $\nu$ on $\mathcal{X}$ is a counting measure if for any $B\in\mathcal{B}_{\mathcal{X}}$, $\nu(B)\in\NN \cup \{+\infty\}$.
    We note $\mathcal{N}_{\mathcal{X}}$ the set of all boundedly finite counting measures on $\mathcal{X}$.
\end{definition}

As done previously, we can equip the space $\mathcal{N}_{\mathcal{X}}$ with a Borel $\sigma$-algebra $\mathcal{B}(\mathcal{N}_{\mathcal{X}})$ generated by the mappings $\nu \mapsto \nu(B)$, for all $B\in\mathcal{B}_{\mathcal{X}}$.

\begin{definition}[Point processes]
    A \emph{point process} $N$ on $\mathcal{X}$ is a measurable mapping from a $(\Omega, \mathcal{F}, \PP)$ into $(\mathcal{N}_{\mathcal{X}}, \mathcal{B}(\mathcal{N}_{\mathcal{X}}))$.
\end{definition}

Intuitively, a point process $N$ is a random measure \parencite[Corollary 1.6.4.]{Baccelli2020} such that, for any $\omega\in\Omega$, the realisation $N(\omega)$ is a counting measure and so in particular all previous results from random measures hold for a point process.
For instance, for any $B\in\mathcal{B}_{\mathcal{X}}$, $N(B)$ will denote the measure of $B$ by $N$, which allows us to introduce the definition of a simple point process.

\begin{definition}
A point process $N$ is \emph{simple} if for any $x\in\mathcal{X}$, $N(\{x\}) \in \{0, 1\}$ a.s.
\end{definition}

It is very common in the literature to work uniquely with simple point processes, but before further discussing this, let us exhibit the following result from the theory of point processes.

\begin{theorem}{\parencite[Corollary 6.5]{Last2017}}\label{th:chap1_point_decomposition}

    Let $N$ be a point process on $\mathcal{X}$ and let $\delta_x$ be the Dirac measure on $x$, for any $x\in\mathcal{X}$.
    There exists a random variable $\kappa\in\NN\cup \{+\infty\}$ and a sequence of random variables $(T_1, T_2, \ldots)$ such that:
    \[N = \sum_{k=1}^{\kappa}{\delta_{T_k}}\,,\quad \text{a.s.}\]  

    We refer to the variables $T_k$ as the \emph{event times} or \emph{points} of process $N$.
\end{theorem}
This theorem reunites the definition of a point process as a random measure with other formalisms of point processes as random points observed in a space $\mathcal{X}$.
A simple point process is then a point process without coinciding points, in other words, for any $i\neq j$, $T_i \neq T_j$ almost surely.
From now on, we will assume that all point processes are simple.

Let us now turn to some particularities of working in a temporal setting. As $\mathcal{X}$ is a well-ordered set, it is practical to order the event times of $N$.
The indexation of the sequence of event times slightly differs whether we work on $\RR_{\geq 0}$ or $\RR$. 
Unlike Theorem~\ref{th:chap1_point_decomposition} may suggest, it is a common adopted convention, when working on the entire real line, that the event times are indexed by $\ZZ$ such that \[\ldots < T_{-2} < T_{-1} < T_{0} \leq 0 < T_1 < T_2 < \ldots\,.\]
This way, positive indices will always denote points \emph{after} the origin of time $t=0$.
Another usual convention is to denote $N(t) = N([0, t])$ the number of points in the interval $[0, t]$ especially used in inference contexts.
This allows also to see $(N(t))_{t\in\mathcal{X}}$ as a right-continuous stochastic process.

\subsection{Integrals and moment measures}

We can define the stochastic integral of a measurable function $f:\mathcal{X}\to \RR_{\geq 0}$ against a point process $N$ with event times $(T_k)_{k\in\ZZ}$ as:
\[\int_{\mathcal{X}}{f(t)\, N(\dd t)} = \sum_{k\in\ZZ}{f(T_k)}\,,\]
which is similar to the Lebesgue-Stieljes integral.
We can see that the integral defined this way is a random variable and by taking $f=\II_{B}$ for any $B\in\mathcal{B}_{\mathcal{X}}$, we can retrieve the measure of $B$:
\[\int_{\mathcal{X}}{\II_{B}(t)\, N(\dd t)} = \sum_{k\in\ZZ}{\II_{T_k \in B}} = N(B)\,.\]

Let us now define the moment measures of $N$.
\begin{definition}
    Let $N$ be a point process. Whenever it exists, we note $M_k$ the \emph{$k$-th moment measure} of $N$ defined, for any $(B_1,\ldots, B_k)\in\mathcal{B}_{\mathcal{X}}^k$, as:
    \[M_k(B_1, \ldots, B_k) = \EE[N(B_1)\ldots N(B_k)]\,.\]

    In particular, the first moment measure $M_1$ is also known as the \emph{intensity measure} of $N$, also denoted $\Lambda$.
\end{definition}
With the intensity measure, we are able to introduce the most classical point process, the Poisson process.

\begin{definition}\label{def:chap1_poisson_process}
    Let $\Lambda$ be a measure on $\mathcal{X}$ absolutely continuous with respect to the Lebesgue measure $\ell$ and let $\lambda:\mathcal{X}\to\RR_{\geq0}$ be its Radon-Nikodym derivative.

    A point process $N$ is a \emph{Poisson process} with intensity function $\lambda$ if it verifies the following conditions:
    \begin{enumerate}
        \item For any $B\in\mathcal{B}_{\mathcal{X}}$, $N(B)$ follows a Poisson distribution with parameter $\Lambda(B) = \int_{B}{\lambda(t)\,\dd t}$.
        \item For any integer $K$ and any set of disjoint Borel sets $(B_k)_{k=1:K}$, the variables $(N(B_k))_{k=1:K}$ are independent.
    \end{enumerate}

    If $\lambda$ is a constant function, then $N$ is called a \emph{homogeneous} Poisson process.
\end{definition}
The Poisson process is sometimes referred to as a process with independent increments because of the second property.
In particular, when the intensity function $\lambda$ is constant, we can further characterise the process by its inter-arrival times.

\begin{theorem}{\parencite[Theorem 7.2]{Last2017}}\label{th:chap1_interarrival_exponential}

    $N$ is a homogeneous Poisson process with intensity $\lambda > 0$ if and only if the inter-arrival times $(T_{k+1} - T_k)_{k\in\ZZ}$ are i.i.d, all following an exponential distribution with parameter $\lambda$.
\end{theorem}
%Campbell ??

\subsection{The conditional intensity function}

In the previous subsection, we defined the Poisson process through its intensity function, which allows to account for different time-dependent dynamics.
The concept that will allow us to properly introduce the Hawkes process is the conditional intensity function.
For this, let us note $\mathcal{H}_t$ the \emph{history} of a point process $N$ up to the instant $t\in\mathcal{X}$. 
$\mathcal{H}_t$ is the $\sigma$-algebra generated by the event times $T_k$:
\[\mathcal{H}_t = \sigma(\{T_k \mid k\in\ZZ, T_k \leq t\})\,.\]

\begin{definition}\label{def:chap1_conditional_intensity}
    Let $N$ be a simple point process on $\mathcal{X}$, and $(\mathcal{H}_t)_{t}$ the histories of $N$.
    The \emph{conditional intensity function} $\lambda$ of $N$ is defined, for any $t\in\mathcal{X}$, as:
    \begin{equation}\label{eq:chap1_conditional_intensity}
        \lambda(t \mid \mathcal{H}_t) = \lim_{h \to 0}{\frac{\EE[N([t,t+h]) \mid \mathcal{H}_t]}{h}}\,.
    \end{equation}
\end{definition}
Let us remark that by Proposition 7.2.IV in \textcite{DaleyV1}, a point process is entirely determined by its conditional intensity function.
In general, the conditional intensity function $\lambda$ is a random variable for each $t\in\mathcal{X}$ as it is expressed through a conditional expectation.
However, if $\lambda$ is a deterministic function, then it coincides with the intensity function of a Poisson process as given in Definition~\ref{def:chap1_poisson_process}, which justifies keeping the same notation $\lambda$. 

It is a common practice to omit the term $\mathcal{H}_t$ in Equation~\eqref{eq:chap1_conditional_intensity} as a conditional intensity is usually understood as having access to the entire past history (unless it is to avoid ambiguity).
Intuitively $\lambda$ quantifies the instantaneous probability of observing a point on an interval of infinitesimal size $h$.
As $N$ is a simple point process, the expectation in Equation~\eqref{def:chap1_poisson_process} corresponds to $\PP(N([t, t+h])) = 1$ for $h$ small enough.
Another common interpretation (see \textcite{Hawkes1971}, for an example) of the conditional intensity function for simple point processes is through the following properties:
\[
    \begin{cases}
\PP(N([t, t+h]) = 1) = \lambda(t) h + o(h)\\
\PP(N([t, t+h]) = 0) = 1 - \lambda(t) h + o(h)\\
\PP(N([t, t+h]) \geq 2)= o(h)\,.
    \end{cases}
\]
A very formal presentation of the conditional intensity function can be found in \textcite[Chapter 7]{DaleyV1} through the concept of Janossy densities.
In a nutshell, given a number $K$ of observed points in a set $B$, the Janossy densities describe the probability distributions of points $(T_k)_{k=1:K}$ inside $B$.

\begin{definition}
    Let $N$ be a simple point process and $\lambda$ its conditional intensity function.
    The \emph{compensator} $\Lambda$ of $N$ is the random measure defined, for any $B\in\mathcal{B}_{\mathcal{X}}$ as:
    \[\Lambda(B) = \int_{B}{\lambda(t)\,\dd t}\,.\]

    In particular, the expectation of $\Lambda$ is the first-order moment measure of $N$.
    If $N$ is stationary, then this measure is a constant multiple of the Lebesgue measure $\ell$.
\end{definition}
Again, the concept of compensator coincides with the intensity measure in Definition~\ref{def:chap1_poisson_process} whenever $\lambda$ is deterministic.
Similarly to the notation of point processes, we note $\Lambda(t) = \Lambda([0,t])$ for any $t\in\mathcal{X}$.
The compensator is a highly studied quantity for point processes defined through conditional intensity functions.
An important result concerning $\Lambda$ is the time change theorem:

\begin{theorem}{\parencite[Theorem 7.4.IV]{DaleyV1}}

    Let $(X_k)_{k\in\ZZ}$ be an a.s.\ increasing sequence of random variables in $\mathcal{X}$ and $\mathcal{F}_t = \sigma(\{X_k \mid k\in\ZZ, X_k\leq t\})$, for all $t\in\RR$.
    Let $\bar\lambda(\cdot\mid \mathcal{F}_{\cdot})$ be a non-negative function such that, for all $t\in\RR$, $\bar\lambda(t\mid \mathcal{F}_{t})$ is $\mathcal{F}_t$-measurable and let $\bar\Lambda$ be defined, for any $t\in\RR$, as:
    \[\bar\Lambda(t) = \int_{-\infty}^{t}{\bar\lambda(u\mid\mathcal{F}_u)\,\dd u}\,.\]

    Then, the process $\sum_{k\in\ZZ}{\delta_{X_k}}$ is a point process with conditional intensity function $\bar\lambda$ if and only if $\sum_{k\in\ZZ}{\delta_{\bar\Lambda(X_k)}}$ is a homogeneous Poisson process with unit intensity.
\end{theorem}
It is then possible to rescale the event times of any observed point process $N$ in order to obtain a realisation of a homogeneous Poisson process.
This is a very useful result in order to establish goodness-of-fit procedures for point processes when an estimation $\hat \Lambda$ of $\Lambda$ is available.
For example, by transforming the observed event times $(T_k)_k$ with $\hat \Lambda$, we can then test whether the inter-arrival times $(\hat \Lambda(T_{k+1}) - \hat \Lambda(T_k))_k$ are exponentially distributed (see Theorem~\ref{th:chap1_interarrival_exponential}).

Lastly, we conclude this section by introducing the expression of the likelihood.

\begin{proposition}{\parencite[Theorem 7.2.III]{DaleyV1}}

    Let $N$ be a point process with conditional intensity function $\lambda$.
    Let $(T_k)_{k=1:N(T)}$ be the realisation of $N$ in the interval $[0, T]$.
    
    Then the likelihood $L_T$ of $N$ reads:
    \begin{equation}\label{eq:chap1_likelihood}
        L_T = \left(\prod_{k=1}^{N(T)}{\lambda(T_k^-)}\right)\mathrm{e}^{-\Lambda(T)}\,,
    \end{equation}
    where $\lambda(T_k^-) = \lim_{t\to T_k^-}(\lambda(t))$.

    The log-likelihood of $N$ is:
    \begin{equation}\label{eq:chap1_loglikelihood}
        \ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,.
    \end{equation}
\end{proposition}
The likelihood can be introduced by means of the Janossy densities.
Let us note that, in the case of point processes on the entire real line $\RR$, it is necessary to know all the points $T_k \leq T$ in order to compute the likelihood, which is usually unavailable.
In practice, it is often assumed that no points occured in $(-\infty, 0)$ and so an adapted version of $\lambda$ is used in Equation~\ref{eq:chap1_likelihood} (see \textcite{Ogata1978}).

\section{Hawkes process}\label{sec:chap1_hawkes_process}

\subsection{The self-exciting Hawkes process}

The Hawkes process, as introduced in \textcite{Hawkes1971}, is defined as a point process in $\RR$ as follows:

\begin{definition}\label{def:chap1_hawkes_process}
    Let $\mu>0$ and $h:\RR_{\geq 0}\to\RR_{\geq 0}$ be a measurable function such that \[\|h\|_1 = \int_{0}^{+\infty}{\lvert h(t)\rvert\,\dd t} < 1\,.\]

    A \emph{Hawkes process} $N$ is a point process on $\RR$ defined by the conditional intensity function:
    \begin{equation}\label{eq:chap1_hawkes_intensity}
        \forall t\in\RR,\qquad \lambda(t) = \mu + \int_{-\infty}^{t}{h(t-s)\,N(\dd s)}\,.
    \end{equation}
    $\mu$ is known as the \emph{baseline intensity} and $h$ as the \emph{interaction} or \emph{kernel function}.
\end{definition}
This process was initially referred to as a self-exciting point process due to the integral in Equation~\eqref{eq:chap1_hawkes_intensity} that represents the positive contribution of all past points up to time $t$ to the intensity function $\lambda$. 
Let us recall that:
\[\int_{-\infty}^{t}{h(t-s)\,N(\dd s)} = \sum_{T_k \leq t}{h(t - T_k)}\,,\]
and so each event time $T_k$ increases the baseline intensity by an additive factor of $h(t - T_k)$, hence the self-excitation effect.
%Image with simulation and say that it is done with method from github

The condition \[\int_{0}^{+\infty}{h(t)\,\dd t} < 1\,,\] for the interaction function ensures that $N$ is boundedly finite a.s. and so that $N$ is a point process.
Another result of this condition is that $\lim_{t\to+\infty}h(t) = 0$, meaning that the effect of any point $T_k$ dissipates the further they are in the past.

Another implication of this condition is that a Hawkes process defined in $\RR$ is a stationary point process \parencite[Lemma 1]{Hawkes1974} which allows to establish the following result.

\begin{proposition}\parencite[Equation (9)]{Hawkes1971}
    Let $N$ be a stationary Hawkes process.
    Then the average intensity of $N$ reads:
    \[\forall t\in\RR,\qquad \EE[\lambda(t)] = \frac{\mu}{1-\|h\|_1}\,.\]
\end{proposition}
The stationarity of process $N$ is verified for processes only in $\RR$ and so this result does not hold for a process in $\RR_{\geq 0}$.
On the one hand, it is often more practical for theoretical reasons to work in $\RR$, as stationarity tends to facilitate establishing certain results (see \textcite{Hawkes1971} for example in the context of spectral theory).
On the other hand, working with a process in $\RR_{\geq 0}$ is often preferred for application purposes, as it is unrealistic to suppose that the practitioner has access to an infinite number of points in the past before $t=0$. To define such a process, it suffices to replace the lower bound in the integral of Equation~\eqref{eq:chap1_hawkes_intensity} by $0$.

%This is a result of stationarity and the Campbell formula for point processes \parencite[Proposition 2.7]{Last2017}. 

\subsection{The multivariate Hawkes process}

The multivariate version of a self-exciting Hawkes process was introduced in \textcite{Hawkes1971} as follows.

\begin{definition}\label{def:chap1_multivariate_hawkes}
    A multivariate Hawkes process $N = (N_1, \ldots, N_d)$ of dimension $d$ is defined by $d$ point processes $(N_i)_{i=1:d}$.
    For each integer $i$, we note $(T_k^i)_k$ the event times of process $N_i$ and its conditional intensity function $\lambda^i$ reads:
    \[\lambda^i(t) = \mu_i + \sum_{j=1}^{d}\int_{-\infty}^{t}{h_{ij}(t-s)}\,N_j(\dd s) = \mu_i + \sum_{j=1}^{d}\sum_{T_k^j \leq t}{h_{ij}(t-T_k^j)}\,.\]
    For any integers $i, j$, $\mu_i>0$ is the baseline intensity of $N_i$ and $h_{ij}\colon\RR_{\geq 0}\to \RR_{\geq 0}$ is a measurable function.
\end{definition}
For a multivariate Hawkes process, each intensity function $\lambda^i$ is influenced by every point $T_k^j$ of process $N_j$, for all integers $j$.
Function $h_{ij}$ represents the influence of a point from $N_j$ to process $N_i$. We define the matrix $S = (\|h_{ij}\|_1)_{1 \geq i,j \geq d}$ and a condition for all $N^i$ to be proper point processes is to control the spectral radius $\rho(S) < 1$ \parencite{Bacry2015}.
This condition ensures again the stationarity of all processes when defined in $\RR$.

When $d=1$, we retrieve the original expression of a Hawkes process from Definition~\ref{def:chap1_hawkes_process} and so we talk about a univariate Hawkes process. 
Defining a multivariate Hawkes process as a tuple is the more common formulation for any kind of point process, but it is sometimes practical to consider process $N$ as the superposition of all subprocesses $N_i$.
$N$ is then characterised by the ordered union of all event times $(T_k^i)_{k\in\ZZ}$ for all integers $i$, forming a single point process in $\RR$ with event times $(T_{(k)})$ and conditional intensity function:

\[\lambda(t) = \sum_{i=1}^{d}{\lambda^i(t)}\,.\]
This perspective allows to extend all results from general point process theory to multivariate processes, including inference methods.

\subsection{Non-linear Hawkes processes}

A more general formulation of a past-dependent point process inspired by the Hawkes process was proposed in \cite{Bremaud1996} and known as the non-linear Hawkes process.

\begin{definition}
    The univariate \emph{non-linear Hawkes process} $N$ on $\RR$ is defined by the conditional intensity function:
    \begin{equation}\label{eq:nonlinear_hawkes_process}
        \lambda(t) = \Phi\left(\mu + \int_{-\infty}^{t}{h(t-s)\,N(ds)}\right)\,,
    \end{equation}
    where $\mu>0$ and $\Phi:\RR \to \RR_{\geq 0}$ and $h\colon \RR_{\geq 0}\to \RR$ are two measurable functions.
    $\Phi$ is known as the activation function and $h$ as the \emph{interaction} or \emph{kernel function}.
\end{definition}
The usual formulation of the self-exciting Hawkes process in Definition~\ref{def:chap1_hawkes_process} can be retrieved by taking the identity function $\Phi\colon x \mapsto x$ and by adding a positivity constraint on $h$. 
Because of this, it is often referred to as the \emph{linear} Hawkes process.

By allowing $h$ to take negative values in Equation~\eqref{eq:nonlinear_hawkes_process}, the non-linear Hawkes process can model an \emph{inhibiting} effect between points where each point decreases the chances of other points occuring, in opposition to the excitation effect.

To guarantee the existence of such a process, either $\Phi$ needs to be upper-bounded or $\Phi$ to be $L$-lipschitz, for $L>0$, such that:
\[L\|h^+\|_1 < 1\,,\]
where $(\cdot)^+\colon x \mapsto \max(0, x)$ denotes the positive part function.

A multivariate version of this process can be defined as for the classical Hawkes process in Definition~\ref{def:chap1_multivariate_hawkes}.
In this setting, existence can be retrieved either by upper-boundness of $\Phi$ or by imposing that the spectral radius of matrix $S^+ = (L \|h_{ij}^+\|_1)_{1 \geq i,j \geq d}$ is stricly smaller than $1$ \parencite[Lemma 2.1]{Sulem2024}.
For instance, if $\Phi$ is the positive part function, this condition can be retrieved by upper-bounding the intensity function by the intensity of the linear process $N^+$ with interaction functions $(h_{ij}^+)_{i,j}$, for all integers $i,j$ \parencite[Theorem 2]{Deutsch2022}.

This function, often called ReLU activation, is the most common choice in the literature for the non-linear function \parencite{Lemonnier2014, Lu2018, Costa2020}, with other examples include clipped exponential \parencite{Chornoboy1988, Carstensen2010}, sigmoid \parencite{Menon2018} and softplus functions \parencite{Mei2017}.
This model of inhibiting interactions for the Hawkes process is often referred to as \emph{additive} inhibition and other works in the literature have proposed alternative versions such as the self-limiting Hawkes process with a multiplicative exponential term dependent on the number of points in a moving interval \parencite{Olinde2020}, and the mean-field Hawkes process with multiplicative inhibition \parencite{Duval2021}.


\section{Inference for Hawkes processes}\label{sec:chap1_inference}

% Estimation for Hawkes processes consists in estimating both the baseline intensity $\mu$ and the interaction function $h$ for a realisation of $N$ in a window $[0,T]$.
% A common optimisation procedure is the maximisation of the log-likelihood:
% \[\ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,,\]
% as shown in \textcite{Ozaki1979} and a multivariate version is presented in \textcite{Embrechts2011, Guo2018} with good mathematical properties including consistency and asymptotic normality \parencite{Clinet2017}, mainly developed in parametric settings.
% We provide an insight of this method in Section~\ref{sec:chap1_exponential_MLE} for an exponential parametrisation of $h$.
% Other methods implemented in parametric settings are the method of moments \parencite{DaFonseca2013}, through spectral analysis \parencite{Adamopoulos1976} or by leveraging the branching structure of Hawkes processes \parencite{Veen2008}.

% Inference procedures in non-parametric settings tend to be based in minimisation a least-squares contrast defined, for an estimator $\hat \lambda$ of the real intensity $\lambda$, as:
% \[\|\hat \lambda - \lambda\|_2^2 = \int_{0}^{T}{(\hat\lambda(t) - \lambda(t))^2\,\dd t}\,,\]
% usually by approximating $h$ through histograms \parencite{Lemonnier2014, Reynaud2014} or by using autoregressive models \parencite{Kirchner2017}. Other methods include solving Wiener-Hopf equations \parencite{Bacry2016}, by optimising a penalised log-likelihood through an EM algorithm \parencite{Lewis2011} or by fitting second and third-order cumulants \parencite{Achab2016}. 
In this section we will review some classical methods for the estimation of the baseline intensity $\mu$ and interaction function $h$ of the linear Hawkes process $N$.
The literature on inference procedures in the non-linear setting is scarcer and some will be mentioned in Section~\ref{sec:chap1_bayesian_estimation}.

\subsection{MLE for Hawkes process with exponential kernel}\label{sec:chap1_exponential_MLE}

A common method is maximisation of the log-likelihood:
\[\ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,,\]
as shown in \textcite{Ozaki1979}. A multivariate version of it is presented in \textcite{Embrechts2011, Guo2018} with expected mathematical properties including consistency and asymptotic normality \parencite{Clinet2017}, mainly developed in parametric settings.

We present here the implementation of the maximum likelihood estimation method for univariate self-exciting Hawkes processes.
Let $N$ be a Hawkes process in $\RR_{\geq 0}$ and we assume that the function $h$ is parametrised by an exponential distribution such that:
\[h(t) = \alpha\mathrm{e}^{-\beta t}\,, \quad \text{for $t\geq 0$,}\]
with $\alpha >0$ and $\beta>0$.
The existence condition in Definition~\ref{def:chap1_hawkes_process} reads:
\[\|h\|_1 = \frac{\alpha}{\beta} < 1\,,\]
and so we assume that $\alpha < \beta$. 
By defining the following parametric model:
\[\mathcal{P} = \left\{
    \lambda_\theta \mid \theta = (\mu, \alpha, \beta)\in\RR_{\geq 0}^3, \alpha < \beta
\right\}\,,\]
the log-likelihood \eqref{eq:chap1_loglikelihood} becomes a function of parameter $\theta$:
\[
    \ell_T(\theta) = \sum_{k=1}^{N(T)}{\log(\lambda_\theta(T_k^-))} - \Lambda_\theta(T)\,,
\]
with $\Lambda_\theta$ the compensator of $\lambda_\theta$.

The choice of the exponential kernel function for $N$ implies that the intensity $\lambda$ is Markovian in the sense that in each interval $[T_k, T_{k+1})$ the expression is solely dependent on the value of $\lambda(T_k)$. For any integer $k\geq 1$ and any $t\in[T_k, T_{k+1})$, the intensity reads:

%The choice of the exponential kernel function for $N$ implies that the intensity $\lambda$ is Markovian in the sense that in each interval $[T_k,T_{k+1})$ the expression is solely dependent on the value of $\lambda(T_k)$. For any integer $k\geq 1$ and any $t\in[T_k,T_{k+1})$, the intensity reads:
\begin{align}
    \lambda(t) = \mu + \int_{0}^{+\infty}{\alpha \mathrm{e}^{-\beta(t-s)}\,N(\dd s)} &= \mu + \sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(t-T_j)}}\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(T_k-T_j)}}\nonumber\\
    %&=\mu + \mathrm{e}^{-\beta(t - T_k)}\left(\mu + \sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(T_k-T_j)}} - \mu\right)\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\left(\lambda(T_k) - \mu\right)\label{eq:chap1_recursive_intensity}\,.
\end{align}
We can then easily integrate $\lambda$ in $[T_k,T_{k+1})$:
\begin{align*}
    \int_{T_k}^{T_{k+1}}{\lambda(t)\,\dd t} &= \mu(T_{k+1} - T_k) + (\lambda(T_k) - \mu) \int_{T_k}^{T_{k+1}}{\mathrm{e}^{-\beta(t - T_k)}\,\dd t}\\
    &= \mu(T_{k+1} - T_k) + (\lambda(T_k) - \mu)\beta^{-1}(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})\,.
\end{align*}

Then, for any interval $[0, T]$, the compensator $\Lambda$ can be computed piecewise:
\begin{align*}
    \Lambda(T) &= \int_{0}^{T}{\lambda(t)\,\dd t}\\
    &= \int_{0}^{T_1}{\mu\,\dd t} + \sum_{k=1}^{N(T)-1}\int_{T_k}^{T_{k+1}}{\lambda(t)\,\dd t} + \int_{T_{N(T)}}^{T}{\lambda(t)\,\dd t}\\
    &= \mu T + \beta^{-1}\left(\sum_{k=1}^{N(T)-1}{(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})} + (\lambda(T_{N(T)}) - \mu)(1 - \mathrm{e}^{-\beta(T - T_k)})\right)\,.
\end{align*}
The consequence of this expression is that the terms $\lambda(T_k)$ (and $\lambda(T_k^-)$) can be computed recursively by Equation~\ref{eq:chap1_recursive_intensity} and so $\Lambda$ has a computational complexity of $O(N(T))$. 
The log-likelihood also has a complexity of $O(N(T))$ and can be efficiently computed as described in Algorithm~\ref{alg:chap_1_loglikelihood}:

\begin{algorithm}[!ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $\alpha$, $\beta$, time horizon $T$ and sequence of event times $(T_k)_{k=1:N(T)}$\;
     \textbf{\underline{Initialization}} Initialize $\ell_T = \log(\mu) - \mu T$, $\lambda(T_1) = \mu + \alpha$\;
     \For{$k \geq 1$}{
        Compute $\lambda(T_{k+1}^-) = \mu + (\lambda(T_k) - \mu)\mathrm{e}^{-\beta(T_{k+1} - T_k)}$\;
        Update $\ell_T = \ell_T + \log(\lambda(T_{k+1}^-) ) - \beta^{-1}(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})$\;
        Compute $\lambda(T_{k+1}) = \lambda(T_{k+1}^-) + \alpha$\;
        }
    Update $\ell_T = \ell_T - \beta^{-1}(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T - T_k)})$\;
     \Return Log-likelihood $\ell_T$
     \caption{Computation of $\ell_T$}
     \label{alg:chap_1_loglikelihood}
\end{algorithm}

In practice, we obtain an estimation $\hat \theta$ of a parameter $\theta = (\mu, \alpha, \beta)$ by maximising the log-likelihood.

Other methods implemented in parametric settings are the method of moments \parencite{DaFonseca2013}, by leveraging the spectral theory of point processes to maximise a spectral version of the log-likelihood \parencite{Adamopoulos1976} or through an Expectation-Maximisation procedure to estimate the branching structure of the Hawkes process \parencite{Veen2008}.

\subsection{Least-squares minimisation}

Inference procedures in non-parametric settings tend to be based on the minimisation of a least-squares contrast.
Let us assume that we want to estimate an intensity function $\lambda$ in an interval $[l, L]$ through a function $\hat \lambda$.
We define the squared error of $\hat \lambda$ as:
\begin{align}
    \|\hat \lambda - \lambda\|_2^2 &= \int_{l}^{L}{(\hat \lambda(t) - \lambda(t))^2\,\dd t}\\
    &= \int_{l}^{L}{\hat \lambda^2(t)\,\dd t} - 2\int_{l}^{L}{\hat \lambda(t)\lambda(t)\,\dd t} + \int_{l}^{L}{\lambda^2(t)\,\dd t}\,.
\end{align}
In order to minimise this quantity with respect to $\hat \lambda$, we need to remove the dependency on $\lambda$ as this quantity is unavailable in estimation contexts.
We may remark that the last term can be completely ignored as it does not depend on $\hat \lambda$ but the middle term has to be treated differently.

As done in \textcite{Reynaud2014}, we can leverage the fact that a valid approximation of $\lambda(t)\,\dd t$ is $N(t)$. 
This is justified by the fact that locally $\EE[N(t)] = \EE[\Lambda(t)]$ and that $\lambda$ is the Stieltjes-Lebesgue derivative of $\Lambda$.
We can then minimise the following expression:
\[\int_{l}^{L}{\hat \lambda^2(t)\,\dd t} - 2\int_{l}^{L}{\hat \lambda(t)N(\dd t)}\,,\]
for an observation of process $N$.

Non-parametric approaches to minimise this quantity tend to approximate the interaction function $h$ by histograms \parencite{Lemonnier2014, Reynaud2014} or by using autoregressive models \parencite{Kirchner2017}.

Other non-parametric methods include solving Wiener-Hopf equations \parencite{Bacry2016}, optimising a penalised log-likelihood through an EM algorithm \parencite{Lewis2011} and fitting second and third-order cumulants \parencite{Achab2016}. 

\subsection{A Bayesian estimation approach}\label{sec:chap1_bayesian_estimation}

The Bayesian approach for the inference of Hawkes processes consists in estimating the posterior distribution for the parameters of the intensity function.
The method we present here follows the procedure by \textcite{Rasmussen2013} which leverages the expression of the likelihood. 
We present an application for the exponential kernel function $h(\cdot) = \alpha \mathrm{e}^{-\beta \cdot}$.

Let $\theta = (\mu, \alpha, \beta)\sim \Pi$ be a random vector of parameters with density $\pi$ and, conditionally on $\theta$, let $N$ be a linear Hawkes process with intensity $\lambda_\theta$ parametrised by $\theta$.
We define the likelihood $L_T$ (Equation~\eqref{eq:chap1_likelihood}) of $N$, in a time window $[0, T]$ and for a history $\mathcal{H}_T$, as:
\[L_T(\theta) = \left(\prod_{k=1}^{N(T)}{\lambda_\theta(T_k^-)}\right)\mathrm{e}^{-\Lambda_\theta(T)}\,.\]

By the Bayes rule, the posterior distribution of $\theta$ conditional on the observation of $N$ in $[0,T]$ admits a density $\pi(\cdot\mid\mathcal{H}_T)$ proportional to the prior $\pi$ and the likelihood $L_T$:
\[\pi(\theta\mid \mathcal{H}_T) \propto \pi(\theta) L_T(\theta)\,.\]
An estimator $\hat \theta = \EE[\theta\mid \mathcal{H}_T]$ can be approximated by sampling the posterior distribution of $\theta\mid\mathcal{H}_T$, which has the advantage of providing credibility intervals.

For this, we implement a Metropolis-Hastings algorithm with multivariate isotropic normal distribution as the proposition kernel.
Let us illustrate the principle with the baseline intensity $\mu$: for a current parameter $\mu_l$, a candidate $\tilde \mu_l\mid \mu_l\sim\mathcal{N}(\mu_l, \sigma^2)$ is sampled and the acceptance ratio reads:
\begin{align*}
    H_\mu = \frac{\pi(\tilde\mu_l, \alpha, \beta)}{\pi(\mu_l, \alpha, \beta)}\left(\prod_{k=1}^{N(T)}\frac{\lambda_{(\tilde \mu_l,\alpha, \beta)}(T_k^-)}{\lambda_{(\mu_l, \alpha, \beta)}(T_k^-)}\right)\mathrm{e}^{-(\tilde\mu_l - \mu_l) T}\,.
\end{align*}
This allows us to obtain approximatively a sample according to the posterior distribution and provides an estimation $\hat \theta$ by averaging.

Further works in Bayesian contexts in the multivariate setting include \textcite{Blundell2012} for Hawkes processes for the study of a social interaction graph, \textcite{Donnet2020} with theoretical results concerning the concentration rates of posterior distributions. These methods have been recently adapted to include inhibition through non-linear Hawkes processes.
In \textcite{Deutsch2022}, the authors propose to compute the log-likelihood by approximating the compensator by a Simpson's rule in a parametric setting.
A non-parametric estimation method is proposed in \textcite{Sulem2024} which derives posterior concentration rates and in \textcite{Sulem2023} through a variational Bayes procedure with a sparsity-inducing paradigm. 


% \[p(N\mid \lambda) = \left(\prod_{k=1}^{N(T)}{\lambda(T_k^-)}\right)\mathrm{e}^{-\Lambda(T)}\,.\] 
% As suggested by our change of notation, the likelihood is a representation of the distribution of event times of process $N$ for a given intensity $\lambda$.
% As one of the examples in the paper, we consider an exponential kernel function $h(\cdot) = \alpha \beta \mathrm{e}^{-\beta \cdot}$ with $\alpha \in(0,1)$, $\beta > 0$.
% By the Bayes rule, it follows that:
% \[p(\mu, \alpha, \beta \mid N) \propto p(\mu, \alpha, \beta) p(N\mid \mu, \alpha, \beta)\,,\]
% where $p(\mu, \alpha, \beta)$ denotes the prior density of the parameters.

% In order to sample from the posterior distribution, a Metropolis-Hastings algorithm can be implemented by defining the Metropolis ratio for each parameter.
% Let us illustrate with the baseline intensity: a candidate $\tilde \mu_k$ is sampled from a normal distribution centered around the current parameter $\mu_k$ and the acceptance ratio reads:
% \begin{align*}
%     H_\mu &=\frac{p(\tilde \mu_k, \alpha, \beta) p(N\mid \tilde \mu_k, \alpha, \beta)}{p(\mu_k, \alpha, \beta) p(N\mid \mu_k, \alpha, \beta)}\\
%     &= \frac{p(\tilde \mu_k, \alpha, \beta)}{p(\mu_k, \alpha, \beta)}\prod_{k=1}^{N(T)}\frac{\lambda_{\hat \mu_k}(T_k^-)}{\lambda_{\mu_k}(T_k^-)}\mathrm{e}^{-\Lambda_{\hat \mu_k}(T) + \Lambda{\mu_k}(T)}\\
%     &=\frac{p(\tilde \mu_k, \alpha, \beta)}{p(\mu_k, \alpha, \beta)}\prod_{k=1}^{N(T)}\frac{\lambda_{\hat \mu_k}(T_k^-)}{\lambda_{\mu_k}(T_k^-)}\mathrm{e}^{-(\hat\mu_k - \mu_k) T}\,.
% \end{align*}
% The subscripts in the intensity function and compensator are used to denote the differing parameters.
% This expression can be expressed for each update, establishing an overall update procedure to obtain an estimation of the posterior distribution of each parameter.

\section{Simulation}\label{sec:chap1_simulation}

\subsection{Ogata's thinning simulation}

The most classic method to simulate point processes with an intensity function $\lambda$ is obtained through a rejection algorithm. An important condition to implement this method is for the intensity function to be upper-bounded by a constant $\lambda^\star$.
We may then simulate $N$ by first simulating a homogeneous Poisson process with intensity $\lambda^\star$ and then keeping each point with probability $\lambda(t) / \lambda^\star$.

In general, it is not possible to find an upper bound for the intensity of a Hawkes process. Additionally, the intensity function is dependent on each simulated point so each time a point appears, the intensity has to be updated. In order to account for these particularities of a Hawkes process, one of the most used methods is Ogata's thinning algorithm \parencite{Ogata1981}.
To simulate the points of a process $N$ in a window of time $[0,T]$ (with the convention that $T_0 = 0$), we implement the following paradigm.

\begin{enumerate}
\item Assume that event time $T_k < T$ has been simulated.
\item Compute an upper bound $\lambda^\star$ of $t\mapsto \lambda(t\mid\mathcal{H}_{T_k})$ on the interval $[T_k, T]$.
\item Simulate a candidate point $t_{cand}$ according to an exponential distribution with mean $1 / \lambda^\star$.
\item Compute the intensity $\lambda(t_{cand})$.
\item Accept the candidate with probability $\lambda(t_{cand}) / \lambda^\star$.
\end{enumerate}
This algorithm generalises the case when a global upper bound is known by allowing for upper bounds to be local instead.

For the simulation of a Hawkes process, we recall that the interaction function $h$ is such that:
\[\|h\|_1 < 1\,,\]
so in particular it is upper-bounded and attains its upper bound noted $\|h\|_{\infty}$. We can then sequentially determine a local upper bound. Without any other constraints on $h$, for a set of simulated event times $(T_1, \ldots, T_k)$, a local upper bound for $t\mapsto \lambda(t\mid\mathcal{H}_{T_k})$ on the interval $[T_k, +\infty]$ (assuming no other points) is given by:
\[\lambda^\star = \mu + k\|h\|_{\infty}\,.\]
This is clearly a very rough bound and can be easily improved under certain conditions, for example if $h$ is a decreasing function. In this case, then $\lambda$ is piecewise decreasing and so the upper bound becomes:
\[\lambda^\star = \lambda(T_k) + h(0)\,.\]
Choosing a smaller upper-bound improves the simulation time by reducing the overall number of candidates and rejections.

Algorithm~\ref{alg:chap1_ogata_simulation} displays the adaptation of Ogata's thinning algorithm to Hawkes processes for a non-increasing interaction function.

\begin{algorithm}[!ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $h$ a non-increasing function, and a stopping criteria (end-time $T$ or maximal number of jumps $N_{max}$)\;
     \textbf{\underline{Initialization}} Initialize $\lambda_k =\mu$, $t_k=0$\ and list of times $\mathcal{T} = \emptyset$\;
     \While{\textnormal{Stopping criteria not fulfilled}}{
     Set $\lambda^\star = \lambda_k$\;
     Generate candidate time $t_{cand} = t_k - \frac{\log(U_1)}{\lambda^\star}$, $U_1\sim U([0,1])$\;
     Compute intensity $\lambda_k = \lambda(t_{cand})$ using sequence of times $\mathcal{T}$\;
     Sample $U_1\sim U([0,1])$\;
     \If{$U_1 \leq \frac{\lambda_k}{\lambda^\star}$}{
            Add $t_{cand}$ to sequence of times $\mathcal{T}$\;
            Update $\lambda_k = \lambda_k + h(0)$\;
         }
     Set $t_k = t_{cand}$\;
     }
     \Return the sequence of jumps $\mathcal{T}$.
     \caption{Thinning algorithm for monotone self-exciting Hawkes process.}
     \label{alg:chap1_ogata_simulation}
\end{algorithm}

\subsection{Simulation through branching theory}

Another simulation algorithm is based on what is called the branching structure of a Hawkes process.
By Definition~\ref{def:chap1_hawkes_process}, the Hawkes process can be seen as a branching Poisson process as described below.
\begin{enumerate}
    \item Let $N_c$ be a homogeneous Poisson process with intensity $\mu$. All event times $(T_k^c)_{k\in\ZZ}$ are known as parents.
    \item Each parent $T_k^c$ generates a subsidiary process of descendants $C_k$ of event times as follows.
    \begin{itemize}
        \item A first generation $C_{k,1}$ is generated as an inhomogenous Poisson process with intensity $h(\cdot - T_k^c)$.
        \item Each child point $t$ in $C_{k,1}$ generates a new generation $C_{k,2}$ inhomogenous Poisson process with intensity $h(\cdot - t)$.
        \item This is repeated for each generated point until no new points are born. 
        $C_k$ is formed by the union of all points in each subprocess $C_{k, j}$.
    \end{itemize}
    \item The process $N$ composed of the ordered union of all parents $(T_k^c)_k$ and all points in every subprocess $(C_k)_{k}$ is a Hawkes process.
\end{enumerate}
Branching Poisson processes were introduced in \textcite{Bartlett1963, Lewis1964} and allow to leverage the theory of branching processes to study Hawkes processes.
In particular, this procedure can be used to simulate a Hawkes process $N$ as presented in Algorithm~\ref{alg:chap1_branching_simulation}.

\begin{algorithm}[ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $h$ a positive function, and an end-time $T$\;
     \textbf{\underline{Initialization}} Initialize list of times $\mathcal{T}$, $t_k=0$ and auxiliary empty list $L_{aux}$\;
     Generate the number of parents $N_0$ according to a Poisson distribution with parameter $\mu T$\;
     Generate parent event times $(T_k^c)_k$ as $N_0$ independent and uniformly distributed points in $[0, T]$, that are then sorted\;
     Add all points $(T_k^c)_k$ to $L_{aux}$ and $\mathcal{T}$\;
     \While{$L_{aux}$ \textnormal{is not empty}}{
        \For{t in $L_{aux}$}{
            Generate a number of children with Poisson distribution of parameter $\|h\|_1$\;
            Generate the children times distributed according to the probability density function $h(\cdot - t)/\|h\|_1$.\;
            Add all points inside the simulation window $[0, T]$ to $L_{aux}$ and $\mathcal{T}$\;
        }    
     }
     \Return Ordered sequence of jumps $\mathcal{T}$.
     \caption{Branching simulation algorithm for self-exciting Hawkes process}
     \label{alg:chap1_branching_simulation}
    \end{algorithm}
The fact that such an algorithm will end, in other words that each subsidiary process will end up by not generating any point, is a direct consequence of the condition $\|h\|_1 < 1$.
This is a result of Galton-Watson process theory, as each point tends to generate on average less than a children, the branches will ``die out'' eventually.

This algorithm presents some advantages when compared to Ogata's procedure.
First, it does not require to compute an upper-bound for the intensity function, which as seen previously, is an important step in Algorithm~\ref{alg:chap1_ogata_simulation}.
Second, this procedure does not have a rejection step and there is no need to compute the value $\lambda$ each time that a point is simulated, which can greatly reduce the overall computation time.
Overall, the only constraint on $h$ imposed by Algorithm~\ref{alg:chap1_branching_simulation} is to be able to simulate according to the probability density function $h(\cdot - t)/\|h\|_1$.
Nevertheless, this method is not longer valid to simulate non-linear Hawkes processes that lack the branching structure of the linear Hawkes process. 