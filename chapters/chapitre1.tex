\leadchapter{
  
}

\chapter[][]{An introduction to Hawkes processes study}\label{chapter:background}

\section{Introduction}

Point processes are a fundamental concept in stochastic modeling, providing a framework for analysing events that occur randomly over time. 
Traditionally, this model is presented through the concept of an ordered collection of random variables in the real line, each one representing the occurrence of an event.
A practical approach to study point processes is by defining random measures, which are random variables with realisations on the space of boundedly finite measures.
In particular, this framework gives access to many results from set theory and measure theory as largely shown in the literature \parencite{Cox1980, Baddeley2006, DaleyV2, Baccelli2020}.

In this chapter, we present a succinct introduction to these concepts in order to present the submodel of past-dependent point processes: the Hawkes model \parencite{Hawkes1971}.
Our goal here is twofold: the first is to introduce numerous notations and definitions that are used throughout this manuscript, serving as a general reference for further chapters. The second is to present a short review of the original self-exciting Hawkes processes and some numerical results from the literature.

We introduce the concept of temporal point processes through random measure theory in Section~\ref{sec:chap1_random_measures} with a particular interest on the concept of conditional intensity functions. 
With this background, we formally introduce the univariate self-exciting Hawkes processes in Section~\ref{sec:chap1_hawkes_process} with the two classical extensions to multivariate settings and the non-linear version, which is often used to model inhibition effects.
We follow up with a general presentation of some classic inference methods in Section~\ref{sec:chap1_inference} and we conclude with Section~\ref{sec:chap1_simulation} by presenting two methods of simulation that are commonly used in the context of Hawkes processes.


\section{Random measures and point processes}\label{sec:chap1_random_measures}

\subsection{Random measures}

Let $\mathcal{X} \subseteq \RR$ denote either the real half-line $\RR_{\geq 0}$ or the real line $\RR$ and $\mathcal{B}_{\mathcal{X}}$ be the Borel $\sigma$-algebra of $\mathcal{X}$.

\begin{definition}
    A measure $\nu$ on $\mathcal{X}$ is said to be \emph{boundedly finite} if for any bounded $B\in\mathcal{B}_{\mathcal{X}}$, $\nu(B) < +\infty$ and we define $\mathcal{M}_{\mathcal{X}}$ as the set of boundedly finite measures on $\mathcal{X}$.
\end{definition}

For both spaces $\mathcal{M}_{\mathcal{X}}$, we may obtain Borel $\sigma$-algebras generated by the mappings $\nu \to \nu(B)$, for all $B\in\mathcal{B}_{\mathcal{X}}$, that we note $\mathcal{B}(\mathcal{M}_{\mathcal{X}})$.

Let $(\Omega, \mathcal{F}, \PP)$ be a probability space.

\begin{definition}[Random measure]
    A \emph{random measure} $\xi$ on $\mathcal{X}$ is a measurable mapping from $\Omega$ into $\mathcal{M}_{\mathcal{X}}$.
    The distribution of a random measure $\xi$ is the probability measure induced by the probability measure $\PP$.
\end{definition}

%In this sense, $\xi$ is a random variable on the measurable set $\mathcal{M}_{\mathcal{X}}$ whose realisation is a deterministic measure on $\mathcal{X}$.
An equivalent definition of a random measure is obtained through the following result:

\begin{proposition}{\parencite[Proposition 1.1.7]{Baccelli2020}}\label{prop:chap1_random_measure_variable}

    For a mapping $\xi:(\Omega, \mathcal{F}) \to (\mathcal{M}_{\mathcal{X}}, \mathcal{B}(\mathcal{M}_{\mathcal{X}}))$, we define for any $B\in\mathcal{B}_{\mathcal{X}}$ the mapping $\xi(B):(\Omega, \mathcal{F}) \to (\mathcal{X}, \mathcal{B}_{\mathcal{X}})$ as:
    \[\xi(B)(\omega) = (\xi(\omega))(B)\,.\]

    Then, $\xi$ is a random measure if and only if, for all $B\in\mathcal{B}_{\mathcal{X}}$, $\xi(B)$ is measurable.
\end{proposition}
With this result, it means that we can work with a random measure $\xi$ in two ways:
\begin{itemize}
    \item For any $\omega\in\Omega$, a realisation $\xi(\omega)$ is a measure on $\mathcal{X}$.
    \item For any $B\in\mathcal{B}_{\mathcal{X}}$, $\xi(B)$ is a random variable on $\mathcal{X}$. Furthermore, $\{\xi(B)\}_{B\in\mathcal{B}_{\mathcal{X}}}$ is a stochastic process.
\end{itemize}
In practice, as with other random variables we tend to omit the term $\omega$ when working with random measures and using $\xi$ either as a measure or random variable is to be understood by the context.
Another direct result from Proposition~\ref{prop:chap1_random_measure_variable} is that, for any finite sequence $(B_k)_{k=1:K}$ of Borel sets, we can define the random vector:
\[(\xi(B_1), \ldots, \xi(B_K))\,.\]
It turns out that a characterisation of any random measure is given by the distribution of all of these vectors:

\begin{proposition}{\parencite[Corollary 9.2.IV]{DaleyV2}}

    Let $\xi$ be a random measure on $\mathcal{X}$. 
    The finite-dimensional distributions of $\xi$ are the probability distribution of the vectors $(\xi(B_1), \ldots, \xi(B_K))$ for all integers $k\geq 1$ and all sequences of Borel sets $(B_k)_{k=1:K}$.

    The distribution of $\xi$ is fully given by its finite-dimensional distributions.
\end{proposition}
With this result, a way of defining any random measure is by defining its finite-dimensional distributions.
However, not any set of finite-dimensional distributions correspond to those of a random measure, but a set of necessary and sufficient conditions is proposed in (cf \parencite[Conditions 9.2.V-VI]{DaleyV2}).
Finally, let us introduce the notion of stationarity. 
For any $B\in\mathcal{B}_{\mathcal{X}}$, for any $x\in\mathcal{X}$, we define $B+x$ as the set:
\[B+x = \{b + x \mid b\in B\}\,.\]

\begin{definition}
    A random measure $\xi$ is said to be \emph{stationary} if 
    for any $B\in\mathcal{B}_{\mathcal{X}}$ and for any $x\in\mathcal{X}$, $N(B)$ and $N(B+x)$ follow the same distribution.
\end{definition}

\subsection{Point processes}

Let us now turn to the study of point processes. For this, we need the definition of a counting measure:

\begin{definition}
    A measure $\nu$ on $\mathcal{X}$ is a counting measure if for any $B\in\mathcal{B}_{\mathcal{X}}$, $\nu(B)\in\NN \cup \{+\infty\}$.
    We note $\mathcal{N}_{\mathcal{X}}$ the set of all boundedly finite counting measures in $\mathcal{X}$.
\end{definition}

As done previously, we can equip the space $\mathcal{N}_{\mathcal{X}}$ with a Borel $\sigma$-algebra $\mathcal{B}(\mathcal{N}_{\mathcal{X}})$ generated by the mappings $\nu \to \nu(B)$, for all $B\in\mathcal{B}_{\mathcal{X}}$.

\begin{definition}[Point processes and simple point processes]
    A \emph{point process} $N$ on $\mathcal{X}$ is a measurable mapping from a $(\Omega, \mathcal{F}, \PP)$ into $(\mathcal{N}_{\mathcal{X}}, \mathcal{B}(\mathcal{N}_{\mathcal{X}}))$.
\end{definition}

Intuitively, a point process $N$ is a random measure \parencite[Corollary 1.6.4.]{Baccelli2020} such that, for any $\omega\in\Omega$, the realisation $N(\omega)$ is a counting measure and so in particular all previous results from random measures hold for a point process.
In particular, for any $B\in\mathcal{B}_{\mathcal{X}}$, $N(B)$ will denote the measure of $B$ by $N$, which allows us to introduce the definition of a simple point process:

\begin{definition}
A point process $N$ is \emph{simple} if for any $x\in\mathcal{X}$, $N(\{x\}) = 1$ a.s.
\end{definition}

It is very common in the literature to work uniquely with simple point processes, but before further discussing this, let us exhibit the following result in the theory of point processes:

\begin{theorem}{\parencite[Corollary 6.5]{Last2017}}\label{th:chap1_point_decomposition}

    Let $N$ be a point process on $\mathcal{X}$ and let $\delta_x$ be the Dirac measure on $x$, for any $x\in\mathcal{X}$.
    There exists a random variable $\kappa\in\NN\cup \{+\infty\}$ and a set of random variables $(T_1, T_2, \ldots)$ such that:
    \[N = \sum_{k=1}^{\kappa}{\delta_{T_k}}\,,\quad \text{a.s.}\]  

    We refer to the variables $T_k$ as the \emph{event times} or \emph{points} of process $N$.
\end{theorem}
This theorem reunites the definition of a point process as a random measure with other formalisms of point processes as random points observed in a space $\mathcal{X}$.
A simple point process is then a point process without coinciding points, in other words, for any $i\neq j$, $T_i \neq T_j$ almost surely.
From now on, we will assume that all point processes from now on are simple.

Let us now turn to some particularities of working in a temporal setting. As $\mathcal{X}$ is a well-ordered set, it is practical to order the event times of $N$.
The indexation of the sequence of event times slightly differs whether we work on $\RR_{\geq 0}$ or $\RR$. 
Unlike Theorem~\ref{th:chap1_point_decomposition} may suggest, it is a common adopted convention, when working on the entire real line, that the event times are indexed by $\ZZ$ such that \[\ldots < T_{-2} < T_{-1} < T_{0} \leq 0 < T_1 < T_2 < \ldots\,.\]
This way, positive indices will always denote points \emph{after} the origin of time $t=0$.
Another usual convention is to denote $N(t) = N([0, t])$ the number of points in the interval $[0, t]$ especially used in inference contexts.
This allows also to see $(N(t))_{t\in\mathcal{X}}$ as a right-continuous stochastic process.

\subsection{Integrals and moment measures}

We can define the stochastic integral of a measurable function $f:\mathcal{X}\to \RR_{\geq 0}$ against a point process $N$ with event times $(T_k)_{k\in\ZZ}$ as:
\[\int_{\mathcal{X}}{f(t)\, N(\dd t)} = \sum_{k\in\ZZ}{f(T_k)}\,,\]
which is similar to the Lebesgue-Stieljes.
We can see that the integral defined as so is a random variable and by taking $f=\II_{B}$ for any $B\in\mathcal{B}_{\mathcal{X}}$, we can retrieve the measure of $B$:
\[\int_{\mathcal{X}}{\II_{B}(t)\, N(\dd t)} = \sum_{k\in\ZZ}{\II_{T_k \in B}} = N(B)\,.\]

Let us now define the moment measures of $N$:
\begin{definition}
    Let $N$ be a point process. Whenever it exists, we note $M_k$ the \emph{$k$-th moment measure} of $N$ defined, for any $(B_1,\ldots, B_k)\in\mathcal{B}_{\mathcal{X}}^k$, as:
    \[M_k(B_1, \ldots, B_k) = \EE[N(B_1)\ldots N(B_k)]\,.\]

    In particular, the first moment measure $M_1$ is also known as the \emph{intensity measure} of $N$, also denoted $\Lambda$.
\end{definition}
With the intensity measure, we are able to introduce the most classical point process: the Poisson process:

\begin{definition}\label{def:chap1_poisson_process}
    Let $\Lambda$ be an absolutely continuous measure on $\mathcal{X}$ with respect to the Lebesgue measure $\ell$ and let $\lambda:\mathcal{X}\to\RR_{>0}$ be its Radon-Nikodym derivative.

    A point process $N$ is a \emph{Poisson process} with intensity function $\lambda$ if it verifies the following conditions:
    \begin{enumerate}
        \item For any $B\in\mathcal{B}_{\mathcal{X}}$, $N(B)$ follows a Poisson distribution with parameter $\Lambda(B) = \lambda \ell(B)$.
        \item For any integer $K$ and any sequence of disjoint Borel sets $(B_k)_{k=1:K}$, the variables $(N(B_k))_{k=1:K}$ are independent.
    \end{enumerate}

    If $\lambda$ is a constant function, then $N$ is called a \emph{homogeneous} Poisson process.
\end{definition}
The Poisson process is sometimes referred to as a process with independent increments because of the second property.
In particular, when the intensity function $\lambda$ is constant, we can further characterise the process by its inter-arrival times:

\begin{theorem}{\parencite[Theorem 7.2]{Last2017}}\label{th:chap1_interarrival_exponential}

    $N$ is a homogeneous Poisson process with intensity $\lambda > 0$ if and only if the inter-arrival times $(T_{k+1} - T_k)_{k\in\ZZ}$ are i.i.d, all following an exponential distribution with parameter $\lambda$.
\end{theorem}
%Campbell ??

\subsection{The conditional intensity function}

In the previous subsection, we defined the Poisson processes through their intensity functions, which allows to account for different time-dependent dynamics.
The concept that will allow us to properly introduce the Hawkes process is the conditional intensity function.
For this, let us note $\mathcal{H}_t$ the \emph{history} of a point process $N$ up to the instant $t\in\mathcal{X}$. 
$\mathcal{H}_t$ is the $\sigma$-algebra generated by the event times $T_k$ such that:
\[\mathcal{H}_t = \sigma(\{T_k \mid k\in\ZZ, T_k \leq t\})\,.\]

\begin{definition}\label{def:chap1_conditional_intensity}
    Let $N$ be a simple point process on $\mathcal{X}$, and $(\mathcal{H}_t)_{t\in\mathcal{H}_t}$ the histories of $N$.
    The \emph{conditional intensity function} $\lambda$ of $N$ is defined, for any $t\in\mathcal{X}$, as:
    \begin{equation}\label{eq:chap1_conditional_intensity}
        \lambda(t \mid \mathcal{H}_t) = \lim_{h \to 0}{\frac{\EE[N([t,t+h]) \mid \mathcal{H}_t]}{h}}\,.
    \end{equation}
\end{definition}
Let us remark that by Proposition 7.2.IV in \textcite{DaleyV1}, a point process is entirely determined by its conditional intensity function.
In general, the conditional intensity function $\lambda$ is a random variable for each $t\in\mathcal{X}$ as it is expressed through a conditional expectation.
However, if $\lambda$ is a deterministic function, then it coincides with the intensity function of a Poisson process as given in Definition~\ref{def:chap1_poisson_process}, which justifies keeping the same notation $\lambda$. 

It is a common practice to omit the term $\mathcal{H}_t$ in Equation~\eqref{eq:chap1_conditional_intensity} as a conditional intensity is usually understood as having access to the entire past history (unless it is to avoid ambiguity).
Intuitively $\lambda$ quantifies the instantaneous probability of observing a point on an interval of infinitesimal size $h$.
As $N$ is a simple point process, the expectation in Equation~\eqref{def:chap1_poisson_process} corresponds with $\PP(N([t, t+h]) = 1)$ for a small enough $h$.
Another common interpretation (see \textcite{Hawkes1971}, for an example) of the conditional intensity function for simple point processes is through the following probabilities:
\[
    \begin{cases}
\PP(N([t, t+h]) = 1) = \lambda(t) h + o(h)\\
\PP(N([t, t+h]) = 0) = 1 - \lambda(t) h + o(h)\\
\PP(N([t, t+h]) \geq 2)= o(h)\,.
    \end{cases}
\]
A very formal presentation of the conditional intensity function can be found in \textcite[Chapter 7]{DaleyV1} through the concept of Janossy densities.
In a nutshell, given a number $K$ of observed points in a set $B$, the Janossy densities describe the probability distribution of points $(T_k)_{k=1:K}$ inside $B$.

\begin{definition}
    Let $N$ be a simple point process and $\lambda$ its conditional intensity function.
    The \emph{compensator} $\Lambda$ of $N$ is the random measure defined, for any $B\in\mathcal{B}_{\mathcal{X}}$ as:
    \[\Lambda(B) = \int_{B}{\lambda(t)\,\dd t}\,.\]

    In particular, $\Lambda$ is the first-order moment measure of $N$.
    If $N$ is stationary, then $\Lambda$ is a constant multiple of the Lebesgue measure $\ell$.
\end{definition}
Again, the concept of compensator coincides with the intensity measure in Definition~\ref{def:chap1_poisson_process} whenever $\lambda$ is deterministic.
Similarly to the notation of point processes, we note $\Lambda(t) = \Lambda([0,t])$ for any $t\in\mathcal{X}$.
The compensator is a highly studied quantity for point processes defined through conditional intensity functions.
An important result concerning $\Lambda$ is the Time Change theorem:

\begin{theorem}{\parencite[Theorem 7.4.IV]{DaleyV1}}

    Let $N$ be a point process with conditional intensity function $\lambda$ and compensator $\Lambda$.
    Let us assume that $\Lambda:t\to \Lambda(t)$ is a continuous, monotone and such that $\lim_{t\to+\infty}\Lambda(t) = +\infty$ a.s.
    Then, the sequence $(T_k)_{k\in\ZZ}$ are the event times of $N$ if and only if $(\Lambda(T_k))_{k\in\ZZ}$ are the event times of a homogeneous Poisson process with intensity $\lambda=1$.
\end{theorem}
It is then possible to rescale the event times of any observed point process $N$ in order to obtain a realisation of a homogeneous Poisson process.
This is an very useful result in order to establish goodness-of-fit procedures for point processes when an estimation $\hat \Lambda$ of $\Lambda$ is available.
For example, by transforming the observed event times $(T_k)_k$ with $\hat \Lambda$, we can then test whether the inter-arrival times $(\hat \Lambda(T_{k+1}) - \hat \Lambda(T_k))_k$ are exponentially distributed (see Theorem~\ref{th:chap1_interarrival_exponential}).

Lastly, we conclude this section by introducing the expression of the likelihood:

\begin{proposition}{\parencite[Theorem 7.2.III]{DaleyV1}}

    Let $N$ be a point process with conditional intensity function $\lambda$.
    Let $(T_k)_{k=1:N(T)}$ be the realisation of $N$ in the interval $[0, T]$.
    
    Then the likelihood $L_T$ of $N$ reads:
    \begin{equation}\label{eq:chap1_likelihood}
        L_T = \left(\prod_{k=1}^{N(T)}{\lambda(T_k^-)}\right)\mathrm{e}^{-\Lambda(T)}\,,
    \end{equation}
    where $\lambda(T_k^-) = \lim_{t\to T_k^-}(\lambda(t))$.

    The log-likelihood of $N$ is:
    \begin{equation}\label{eq:chap1_loglikelihood}
        \ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,.
    \end{equation}
\end{proposition}
The likelihood can be introduced by means of the Janossy densities.
Let us note that, in the case of point processes on the entire real line $\RR$, the conditional intensity function necessitates to know the location of all points in the past before $T$ in order to compute the likelihood, which is usually unavailable.
In practice, it is often assumed that no points occured in $(-\infty, 0)$ and so an adapted version of $\lambda$ is used in Equation~\ref{eq:chap1_likelihood} (see \textcite{Ogata1978}).

\section{Hawkes process}\label{sec:chap1_hawkes_process}

\subsection{The self-exciting Hawkes process}

The Hawkes process, as introduced in \textcite{Hawkes1971}, is defined as a point process in $\RR$ as follows:

\begin{definition}\label{def:chap1_hawkes_process}
    Let $\mu>0$ and $h:\RR_{\geq 0}\to\RR_{\geq 0}$ be a measurable function such that \[\|h\|_1 = \int_{0}^{+\infty}{h(t)\,\dd t} < 1\,.\]

    A \emph{Hawkes process} $N$ is a point process defined by the conditional intensity function:
    \begin{equation}\label{eq:chap1_hawkes_intensity}
        \lambda(t) = \mu + \int_{-\infty}^{t}{h(t-s)\,N(\dd s)}\,.
    \end{equation}
    $\mu$ is known as the \emph{baseline intensity} and $h$ as the \emph{interaction} or \emph{kernel function}.
\end{definition}
This process was initially referred to as a self-exciting point process due to the integral in Equation~\eqref{eq:chap1_hawkes_intensity} that represents the contribution of all past points up to time $t$ to the intensity function $\lambda$. In order to define a Hawkes process in $\RR_{\geq 0}$, it suffices to replace the lower bound in the integral by $0$.
Let us recall that:
\[\int_{-\infty}^{t}{h(t-s)\,N(\dd s)} = \sum_{T_k \leq t}{h(t - T_k)}\,,\]
and so each event time $T_k$ increases the baseline intensity by an additive factor of $h(t - T_k)$, hence the self-excitation effect.
%Image with simulation and say that it is done with method from github

The condition \[\int_{0}^{+\infty}{h(t)\,\dd t} < 1\,,\] for the interaction function ensures that $N$ is boundedly finite a.s. and so that $N$ is a point process.
Another result of this condition is that $\lim_{t\to+\infty}h(t) = 0$, meaning that the effect of any point $T_k$ dissipates the further they are in the past.

Another implication of this condition is that a Hawkes process defined in $\RR$ is a stationary point process which allows to establish the following result:

\begin{proposition}
    Let $N$ be a stationary Hawkes process.
    Then the average intensity of $N$ reads:
    \[\EE[\lambda(t)] = \frac{\mu}{1-\|h\|_1}\,.\]
\end{proposition}
The stationarity of process $N$ is verified for processes only in $\RR$ and so this result does not hold for a process in $\RR_{\geq 0}$.
On the one hand, it is often more practical for theoretical reasons to work in $\RR$, as stationarity tends to facilitate establishing certain results (see \textcite{Hawkes1971} for example in the context of spectral theory).
On the other hand, a process in $\RR_{\geq 0}$ is often preferred for application purposes, as it is unrealistic to suppose that the practitioner has access to an infinite number of points in the past before $t=0$.

%This is a result of stationarity and the Campbell formula for point processes \parencite[Proposition 2.7]{Last2017}. 

\subsection{The multivariate Hawkes process}

The multivariate version of a self-exciting Hawkes process was simultaneously introduced in \textcite{Hawkes1971} as follows: 

\begin{definition}\label{def:chap1_multivariate_hawkes}
    We define a multivariate Hawkes process $N = (N_1, \ldots, N_d)$ of dimension $d$ is defined by $d$ point processes $(N_i)_{i=1:d}$.
    For each integer $i$, we note $T_k^i$ the event times of process $N_i$ and its conditional intensity function $\lambda^i$ reads:
    \[\lambda^i(t) = \mu_i + \sum_{j=1}^{d}\int_{-\infty}^{t}{h_{ij}(t-s)}\,N_j(\dd s)\,.\]
    For any integer $i$, $\mu_i>0$ is the baseline intensity of $N_i$ and $h_{ij}\colon\RR_{\geq 0}\to \RR_{\geq 0}$ is a measurable function.
\end{definition}
For a multivariate Hawkes process, each intensity function $\lambda^i$ is influenced by every point $T_k^j$ of process $N_j$, for all integers $j$.
Function $h_{ij}$ represents the influence of a point from $N_j$ to process $N_i$. We define the matrix $S = (\|h_{ij}\|_1)_{1 \geq i,j \geq d}$ and a condition for all $N^i$ to be proper point processes is to control the spectral radius $\rho(S) < 1$ \parencite{Bacry2015}.
This condition ensures again the stationarity of all processes when defined in $\RR$.

When $d=1$, we retrieve the original expression of a Hawkes process from Defintion~\ref{def:chap1_hawkes_process} and so we talk about an univariate Hawkes process. 
Defining a multivariate Hawkes process as a vector is the more common formulation for any kind of point process, but it is sometimes practical to consider process $N$ as the superposition of all subprocesses $N_i$.
$N$ is then characterised by the ordered union of all event times $(T_k^i)_{k\in\ZZ}$ for all integers $i$, forming a single point process in $\RR$ with event times $(T_{(k)})$ and conditional intensity function:

\[\lambda(t) = \sum_{i=1}^{d}{\lambda^i(t)}\,.\]
This perspective allows to extend any result from general point process theory to a multivariate process $N$, including inference methods.

\subsection{Non-linear Hawkes processes}

A more general formulation of a past dependent point process inspired by the Hawkes process was proposed in \cite{Bremaud1996} known as the non-linear Hawkes process.

\begin{definition}
    The univariate \emph{non-linear Hawkes process} $N$ on $\RR$ is defined by the conditional intensity function:
    \begin{equation}\label{eq:nonlinear_hawkes_process}
        \lambda(t) = \Phi\left(\int_{-\infty}^{t}{h(t-s)\,N(ds)}\right)\,,
    \end{equation}
    for $\Phi:\RR \to \RR_{\geq 0}$ and $h\colon \RR_{\geq 0}\to \RR$ two measurable functions.
    $\Phi$ is known as the activation function and $h$ as the \emph{interaction} or \emph{kernel function}.
\end{definition}
The usual formulation of the self-exciting Hawkes process in Definition~\ref{def:chap1_hawkes_process} can be retrieved by taking the linear function $\Phi\colon x \to \mu + x$ for $\mu>0$ and by adding a positivity constraint on $h$. 
Because of this, it is often referred to as the \emph{linear} Hawkes process.

By allowing $h$ to take negative values in Equation~\eqref{eq:nonlinear_hawkes_process}, the non-linear Hawkes process can model an \emph{inhibiting} effect between points where each point decreases the chances of other points occuring, in opposition to the excitation effect.

To guarantee the existence of such a process, either $\Phi$ needs to be upper-bounded or $\Phi$ to be $L$-lipschitz such that:
\[L\|h^+\|_1 < 1\,,\]
where $(\cdot)^+\colon x \to \max(0, x)$ denotes the positive part function.

A multivariate version of this process can be defined as for the classical Hawkes process in Definition~\ref{def:chap1_multivariate_hawkes}.
In this setting, existence can be retrieved either by upper-boundness of $\Phi$ or by imposing that the spectral radius of matrix $S^+ = (L \|h_{ij}^+\|_1)_{1 \geq i,j \geq d}$ is stricly smaller than $1$ \parencite[Lemma 2.1]{Sulem2024}.

The most common choice for the non-linear function is the positive part function, often called a ReLU activation function \parencite{Lemonnier2014, Lu2018, Costa2020}, with other examples including clipped exponential \parencite{Chornoboy1988, Carstensen2010}, sigmoid \parencite{Menon2018} and softplus functions \parencite{Mei2017}.

\section{Inference for Hawkes processes}\label{sec:chap1_inference}

% Estimation for Hawkes processes consists in estimating both the baseline intensity $\mu$ and the interaction function $h$ for a realisation of $N$ in a window $[0,T]$.
% A common optimisation procedure is the maximisation of the log-likelihood:
% \[\ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,,\]
% as shown in \textcite{Ozaki1979} and a multivariate version is presented in \textcite{Embrechts2011, Guo2018} with good mathematical properties including consistency and asymptotic normality \parencite{Clinet2017}, mainly developed in parametric settings.
% We provide an insight of this method in Section~\ref{sec:chap1_exponential_MLE} for an exponential parametrisation of $h$.
% Other methods implemented in parametric settings are the method of moments \parencite{DaFonseca2013}, through spectral analysis \parencite{Adamopoulos1976} or by leveraging the branching structure of Hawkes processes \parencite{Veen2008}.

% Inference procedures in non-parametric settings tend to be based in minimisation a least-squares contrast defined, for an estimator $\hat \lambda$ of the real intensity $\lambda$, as:
% \[\|\hat \lambda - \lambda\|_2^2 = \int_{0}^{T}{(\hat\lambda(t) - \lambda(t))^2\,\dd t}\,,\]
% usually by approximating $h$ through histograms \parencite{Lemonnier2014, Reynaud2014} or by using autoregressive models \parencite{Kirchner2017}. Other methods include solving Wiener-Hopf equations \parencite{Bacry2016}, by optimising a penalised log-likelihood through an EM algorithm \parencite{Lewis2011} or by fitting second and third-order cumulants \parencite{Achab2016}. 
In this section we will review some classical methods for the estimation of the baseline intensity $\mu$ and interaction function $h$ of a Hawkes process $N$.

\subsection{MLE for Hawkes process with exponential kernel}\label{sec:chap1_exponential_MLE}

A common optimisation procedure is the maximisation of the log-likelihood:
\[\ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,,\]
as shown in \textcite{Ozaki1979} and a multivariate version is presented in \textcite{Embrechts2011, Guo2018} with good mathematical properties including consistency and asymptotic normality \parencite{Clinet2017}, mainly developed in parametric settings.

We present here the implementation of the maximum likelihood estimation method for univariate self-exciting Hawkes processes.
Let $N$ be a Hawkes process in $\RR_{\geq 0}$ and we assume that the function $h$ is parametrised by an exponential distribution such that:
\[h(t) = \alpha\mathrm{e}^{-\beta t}\,, \quad \text{for $t\geq 0$,}\]
with $\alpha >0$ and $\beta>0$.
The existence condition in Definition~\ref{def:chap1_hawkes_process} reads:
\[\|h\|_1 = \frac{\alpha}{\beta} < 1\,,\]
and so we assume that $\alpha < \beta$. 
By defining the following parametric model:
\[\mathcal{P} = \left\{
    \lambda_\theta \mid \theta = (\mu, \alpha, \beta)\in\RR_{\geq 0}^3, \alpha < \beta
\right\}\,,\]
the log-likelihood \eqref{eq:chap1_loglikelihood} becomes a function of parameter $\theta$:
\[
    \ell_T(\theta) = \sum_{k=1}^{N(T)}{\log(\lambda_\theta(T_k^-))} - \Lambda_\theta(T)\,,
\]
with $\Lambda_\theta$ the compensator of $\lambda_\theta$.

The choice of the exponential kernel function for $N$ implies that the intensity $\lambda$ is Markovian in the sense that in each interval $[T_k,T_{k+1})$ the expression is solely dependent on the value of $\lambda(T_k)$.
For any integer $k\geq 1$ and any $t\in[T_k,T_{k+1})$, the intensity reads:
\begin{align}
    \lambda(t) = \mu + \int_{0}^{+\infty}{\alpha \mathrm{e}^{-\beta(t-s)}\,N(\dd s)} &= \mu + \sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(t-T_j)}}\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(T_k-T_j)}}\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\left(\mu + \sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(T_k-T_j)}} - \mu\right)\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\left(\lambda(T_k) - \mu\right)\label{eq:chap1_recursive_intensity}\,.
\end{align}
We can then easily integrate $\lambda$ in $[T_k,T_{k+1})$:
\begin{align*}
    \int_{T_k}^{T_{k+1}}{\lambda(t)\,\dd t} &= \mu(T_{k+1} - T_k) + (\lambda(T_k) - \mu) \int_{T_k}^{T_{k+1}}{\mathrm{e}^{-\beta(t - T_k)}\,\dd t}\\
    &= \mu(T_{k+1} - T_k) + (\lambda(T_k) - \mu)\beta^{-1}(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})
\end{align*}

Then, for any interval $[0, T]$, the compensator $\Lambda$ can be computed piecewise:
\begin{align*}
    \Lambda(T) &= \int_{0}^{T}{\lambda(t)\,\dd t}\\
    &= \int_{0}^{T_1}{\mu\,\dd t} + \sum_{k=1}^{N(T)-1}\int_{T_k}^{T_{k+1}}{\lambda(t)\,\dd t} + \int_{T_{N(T)}}^{T}{\lambda(t)\,\dd t}\\
    &= \mu T + \beta^{-1}\left(\sum_{k=1}^{N(T)-1}{(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})} + (\lambda(T_{N(T)}) - \mu)(1 - \mathrm{e}^{-\beta(T - T_k)})\right)\,.
\end{align*}
The importance of this expression is that the terms $\lambda(T_k)$ (and $\lambda(T_k^-)$) can be computed recursively by Equation~\ref{eq:chap1_recursive_intensity} and so $\Lambda$ has a computational complexity of $O(N(T))$. 
The log-likelihood also has a complexity of $O(N(T))$ and can be efficiently computed as described in Algorithm~\ref{alg:chap_1_loglikelihood}:

\begin{algorithm}[ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $\alpha$, $\beta$, time horizon $T$ and sequence of event times $(T_k)_{k=1:N(T)}$\;
     \textbf{\underline{Initialization}} Initialize $\ell_T = \log(\mu) - \mu T$, $\lambda(T_k) = \mu + \alpha$ and $T_{k} = T_1$\;
     \For{k > 2}{
        Compute $\lambda(T_{k+1}^-) = \mu + (\lambda(T_k) - \mu)\mathrm{e}^{-\beta(T_{k+1} - T_k)}$\;
        Update $\ell_T = \ell_T + \log(\lambda(T_{k+1}^-) ) - \beta^{-1}(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})$\;
        Update $\lambda(T_k) = \lambda(T_{k+1}^-) + \alpha$\;
        Update $T_k = T_{k+1}$\;
        }
    Update $\ell_T = \ell_T - \beta^{-1}(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T - T_k)})$\;
     \Return Log-likelihood $\ell_T$
     \caption{Computation of $\ell_T$}
     \label{alg:chap_1_loglikelihood}
\end{algorithm}

In practice, we obtain an estimation $\hat \theta$ of a parameter $\theta = (\mu, \alpha, \beta)$ by maximising the log-likelihood.

Other methods implemented in parametric settings are the method of moments \parencite{DaFonseca2013}, through spectral analysis \parencite{Adamopoulos1976} or by leveraging the branching structure of Hawkes processes \parencite{Veen2008}.

\subsection{Least-squares minimisation}

Inference procedures in non-parametric settings tend to be based in the minimisation of a least-squares contrast.
Let us assume that we want to estimate an intensity function $\lambda$ in an interval $[l, L]$ through a function $\hat \lambda$.
We define the squared error of $\hat \lambda$ as:
\begin{align}
    \|\hat \lambda - \lambda\|_2^2 &= \int_{l}^{L}{(\hat \lambda(t) - \lambda(t))^2\,\dd t}\\
    &= \int_{l}^{L}{\hat \lambda^2(t)\,\dd t} - 2\int_{l}^{L}{\hat \lambda(t)\lambda(t)\,\dd t} + \int_{l}^{L}{\lambda^2(t)\,\dd t}\,.
\end{align}
In order to minimise this quantity with respect to $\hat \lambda$, we need to remove the dependance on $\lambda$ as this quantity is unavailable in estimation contexts.
We may remark that the last term can be completely ignored as it does not depend on $\hat \lambda$ but the middle term has to be treated differently.

As done in \textcite{Reynaud2014}, we can leverage the fact that a valid approximation of $\lambda(t)\,\dd t$ is $N(t)$. 
This is justified by the fact that locally $\EE[N(t)] = \Lambda(t)$ and that $\lambda$ is the Stieltjes-Lebesgue derivative of $\Lambda$.
We can then minimise the following expression:
\[\int_{l}^{L}{\hat \lambda^2(t)\,\dd t} - 2\int_{l}^{L}{\hat \lambda(t)N(\dd t)}\,,\]
for an observation of process $N$.

Non-parametric approaches to minimise this quantity tend to approximate the interaction function $h$ by histograms \parencite{Lemonnier2014, Reynaud2014} or by using autoregressive models \parencite{Kirchner2017}.

Other non-parametric methods include solving Wiener-Hopf equations \parencite{Bacry2016}, by optimising a penalised log-likelihood through an EM algorithm \parencite{Lewis2011} or by fitting second and third-order cumulants \parencite{Achab2016}. 

\subsection{A Bayesian estimation approach}

The Bayesian approach for the inference of Hawkes processes consists on establishing estimating the posterior distribution for the parameters of the intensity function.
The method we present here follows the procedure in \textcite{Rasmussen2013} by leveraging the expression of the likelihood \eqref{eq:chap1_likelihood}:
\[p(N\mid \lambda) = \left(\prod_{k=1}^{N(T)}{\lambda(T_k^-)}\right)\mathrm{e}^{-\Lambda(T)}\,.\] 
As suggested by our change of notation, the likelihood is a representation of the distribution of event times of process $N$ for a given intensity $\lambda$.
As one of the examples in the paper, we consider an exponential kernel function $h(\cdot) = \alpha \beta \mathrm{e}^{-\beta \cdot}$ with $\alpha \in(0,1)$, $\beta > 0$.
By the Bayes rule, it follows that:
\[p(\mu, \alpha, \beta \mid N) \propto p(\mu, \alpha, \beta) p(N\mid \mu, \alpha, \beta)\,,\]
where $p(\mu, \alpha, \beta)$ denotes the prior distribution on the parameters.

In order to sample from the posterior distribution, a Metropolis-Hastings algorithm can be implemented by defining the Hastings ratio for each parameter.
Let us illustrate with the baseline intensity: a candidate $\tilde \mu_k$ is sampled from a normal distribution centered around the current parameter $\mu_k$ and the acceptance ratio reads:
\begin{align*}
    H_\mu &=\frac{p(\tilde \mu_k, \alpha, \beta) p(N\mid \tilde \mu_k, \alpha, \beta)}{p(\mu_k, \alpha, \beta) p(N\mid \mu_k, \alpha, \beta)}\\
    &= \frac{p(\tilde \mu_k, \alpha, \beta)}{p(\mu_k, \alpha, \beta)}\prod_{k=1}^{N(T)}\frac{\lambda_{\hat \mu_k}(T_k^-)}{\lambda_{\mu_k}(T_k^-)}\mathrm{e}^{-\Lambda_{\hat \mu_k}(T) + \Lambda{\mu_k}(T)}\\
    &=\frac{p(\tilde \mu_k, \alpha, \beta)}{p(\mu_k, \alpha, \beta)}\prod_{k=1}^{N(T)}\frac{\lambda_{\hat \mu_k}(T_k^-)}{\lambda_{\mu_k}(T_k^-)}\mathrm{e}^{-(\hat\mu_k - \mu_k) T}\,.
\end{align*}
The subscripts in the intensity function and compensator are used to denote the differing parameter.
This expression can be expressed for each update, establishing an overall update procedure to obtain an estimation the posterior distribution of each parameter.

Further works in Bayesian contexts in the multivariate setting include \textcite{Blundell2012} for Hawkes processes for the study of a social interaction graph, \textcite{Donnet2020} with theoretical results concerning the concentration rates of posterior distributions. This methods have been recently adapted to include inhibition through non-linear Hawkes as shown in \textcite{Deutsch2022, Sulem2024}. 

\section{Simulation}\label{sec:chap1_simulation}

\subsection{Ogata's thinning simulation}

The most classical method to simulate point processes with an intensity function $\lambda$ is obtained through a rejection algorithm. An important condition to implement this method is to for the intensity function to be upper-bounded by a constant $\lambda^\star$.
We may then simulate $N$ by first simulating a homogeneous Poisson process with intensity $\lambda^\star$ and then thinning each point with probability $\lambda(t) / \lambda^\star$.

In general, it is not possible to find an upper bound for the intensity of a Hawkes processe. Additionally, the intensity function is dependent on each simulated point so each time a point appears, it has to be updated. In order to account for these particularities of a Hawkes process, one of the most used methods is Ogata's thinning algorithm \parencite{Ogata1981}.
To simulate the points of a process $N$ in a window of time $[0,T]$ (with the convention that $T_0 = 0$), we follow the following paradigm:

\begin{enumerate}
\item Assume that event time $T_k < T$ has been simulated.
\item Estimate an upper bound $\lambda^\star$ of $\lambda$ on the interval $[T_k, T]$.
\item Simulate a candidate point $t_{cand}$ according to an exponential distribution with mean $1 / \lambda^\star$.
\item Compute the intensity $\lambda(t_{cand})$
\item Accept the candidate with probability $\lambda(t_{cand}) / \lambda^\star$.
\end{enumerate}
This algorithm generalises the case where a global upper bound is known by allowing for upper bounds to instead be local.

For the simulation of a Hawkes process, we recall that the interaction function $h$ is such that:
\[\|h\|_1 < 1\,,\]
so in particular it is upper-bounded and attains its upper bound noted $\|h\|_{\infty}$. We can then sequentially determine an upper bound. Without any other constraints on $h$, for a set of simulated event times $(T_1, \ldots, T_k)$, an upper bound for $\lambda$ on the interval $[T_k, +\infty]$ (assuming no other points) is given by:
\[\lambda^\star = \mu + k\|h\|_{\infty}\,.\]
This is clearly a very rough bound and can be easily improved under certain conditions, for example if $h$ is a decreasing function. In this case, then $\lambda$ is piecewise decrasing and so the upper bound becomes:
\[\lambda^\star = \lambda(T_k) + h(0)\,.\]
Choosing a smaller upper-bound improves the simulation time by reducing the overall number of candidates and rejections.

Algorithm~\ref{alg:chap1_ogata_simulation} displays the adaptation of Ogata's thinning algorithm to Hawkes processes for a monotone interaction function.

\begin{algorithm}[!ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $h$ a monotone function, and a stopping criteria (end-time $T$ or maximal number of jumps $N_{max}$)\;
     \textbf{\underline{Initialization}} Initialize $\lambda_k =\mu$, $t_k=0$\ and list of times $\mathcal{T} = \emptyset$\;
     \While{\textnormal{Stopping criteria not fulfilled}}{
     Set $\lambda^\star = \lambda_k$\;
     Generate candidate time $t_{cand} = t_k - \frac{\log(U_1)}{\lambda^\star}$, $U_1\sim U([0,1])$\;
     Compute intensity $\lambda_k = \lambda(t_{cand})$ using sequence of times $\mathcal{T}$\;
     Sample $U_1\sim U([0,1])$\;
     \If{$U_1 \leq \frac{\lambda_k}{\lambda^\star}$}{
            Add $t_{cand}$ to sequence of times $\mathcal{T}$\;
            Update $\lambda_k = \lambda_k + h(0)$\;
         }
     Set $t_k = t_{cand}$\;
     }
     \Return the sequence of jumps $\mathcal{T}$.
     \caption{Thinning algorithm for monotone self-exciting Hawkes process.}
     \label{alg:chap1_ogata_simulation}
\end{algorithm}

\subsection{Simulation through branching theory}

Another simulation algorithm is based on what is called the branching structure of a Hawkes process.
By Definition~\ref{def:chap1_hawkes_process}, the Hawkes process can be seen as a branching Poisson process as described below:
\begin{enumerate}
    \item Let $N_c$ be a homogeneous Poisson process with intensity $\mu$. All event times $(T_k^c)_{k\in\ZZ}$ are known as parents.
    \item Each parent $T_k^c$ generates a subsidiary process of descendants $C_k$ of event times as follows:
    \begin{itemize}
        \item A first generation $C_{k,1}$ is generated as an inhomogenous Poisson process with intensity $h(\cdot - T_k^c)$.
        \item Each child point $t$ in $C_{k,1}$ generates a new generation $C_{k,2}$ inhomogenous Poisson process with intensity $h(\cdot - t)$.
        \item This is repeated for each generated point until no new points are born. 
        $C_k$ is formed by the union of all points in each subprocess $C_{k, j}$
    \end{itemize}
    \item The process $N$ composed of the ordered union of all parents $(T_k^c)_k$ and all points in every subprocess $(C_k)_{k}$ is a Hawkes process.
\end{enumerate}
The branching Poisson processes were introduced in \textcite{Lewis1969} and allows to leverage the theory of branching processes to study Hawkes processes.
In particular, this procedure can be used to simulate a Hawkes process $N$ as presented in Algorithm~\ref{alg:chap1_branching_simulation}:

\begin{algorithm}[ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $h$ a positive function, and an end-time $T$\;
     \textbf{\underline{Initialization}} Initialize list of times $\mathcal{T}$, $t_k=0$ and auxiliary empty list $L_{aux}$\;
     Generate the number of parents $N_0$ according to a Poisson distribution with parameter $\mu T$\;
     Generate parent event times $T_k^c$ as $N_0$ independent and uniformly distributed points in $[0, T]$\;
     Update $L_{aux} = C_{k,j}$\;
     Add all points $(T_k^c)$ to $\mathcal{T}$\;
     \While{$L_{aux}$ \textnormal{is not empty}}{
        \For{t in $L_{aux}$}{
            Generate a number of children $\|h\|_1$\;
            Generate the children times distributed according to the probability density function $h(\cdot - t)/\|h\|_1$.
            Add all points inside the simulation window $[0, T]$ to $L_{aux}$ and $\mathcal{T}$\;
        }    
     }
     \Return Ordered sequence of jumps $\mathcal{T}$
     \caption{Branching simulation algorithm for self-exciting Hawkes process}
     \label{alg:chap1_branching_simulation}
    \end{algorithm}
The fact that such an algorithm will end, in other words that each subsidiaty process will end up by not generating any point, is a direct consequence of the condition $\|h\|_1 < 1$.
This is a result of Galton-Watson process theory, as each point tends to generate on average less than a children, the branches will "die out" eventually.

This algorithm presents some advantages when compared to Ogata's procedure.
First, it does not require to compute an upper-bound for the intensity function, which as seen previously, is an important step in Algorithm~\ref{alg:chap1_ogata_simulation}.
Second, this procedure does not have a rejection step and there is no need to compute the value $\lambda$ each time that a point is simulated, which can greatly reduce the overall computation time.
Overall, the only constraint on $h$ imposed by Algorithm~\ref{alg:chap1_branching_simulation} is to be able to simulate accordingly to the probability density function $h(\cdot - t)/\|h\|_1$, unlike the thinning algorithm whose simulation time is greatly dependent on the choice of $h$.