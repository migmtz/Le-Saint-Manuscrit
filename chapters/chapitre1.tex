\leadchapter{
  
}

\chapter[][]{An introduction to Hawkes processes study}\label{chapter:background}

\section{Introduction}

In this chapter, we present a succinct introduction of temporal point processes with notation and definitions that can be used as a general reference for this manuscript.
In the literature of point processes, it is common to navigate concepts between probability theory and measure theory.

The approach that we prefer here is through the theory of random measures.
Random measures provide a general framework that (...)

The different concepts and results presented here are issued from different works on the literature \parencite{Cox1980, Baddeley2006, DaleyV2, Baccelli2020}. 
Our goal is to provide a main reference for some classic concepts of point processes and Hawkes processes that are often used in the following chapters.

We introduce the concept of point processes through random measure theory in Section~\ref{sec:chap1_random_measures} with a particular interest on temporal point processes defined through intensity functions. 
In Section~\ref{sec:chap1_hawkes_process} we formally introduce the Hawkes processes, first for the original formulation with exciting interactions, and second by presenting the concept of non-linear Hawkes processes. 
We follow up with a general introduction of some classic inference methods in Section~\ref{sec:chap1_inference} and we conclude with Section~\ref{sec:chap1_simulation} by presenting two methods of simulation that are commonly used in the context of Hawkes processes

\section{Random measures and point processes}\label{sec:chap1_random_measures}

\subsection{Random measures}

Let $\mathcal{X} \subseteq \RR$ denote either the real half-line $\RR_{\geq 0}$ or the real line $\RR$ and $\mathcal{B}_{\mathcal{X}}$ be the Borel $\sigma$-algebra of $\mathcal{X}$.

\begin{definition}
    A measure $\nu$ on $\mathcal{X}$ is said to be \emph{boundedly finite} if for any bounded $B\in\mathcal{B}_{\mathcal{X}}$, $\nu(B) < +\infty$ and we define $\mathcal{M}_{\mathcal{X}}$ as the set of boundedly finite measures on $\mathcal{X}$.
\end{definition}

For both spaces $\mathcal{M}_{\mathcal{X}}$, we may obtain Borel $\sigma$-algebras generated by the mappings $\nu \to \nu(B)$, for all $B\in\mathcal{B}_{\mathcal{X}}$, that we note $\mathcal{B}(\mathcal{M}_{\mathcal{X}})$.

Let $(\Omega, \mathcal{F}, \PP)$ be a probability space.

\begin{definition}[Random measure]
    A \emph{random measure} $\xi$ on $\mathcal{X}$ is a measurable mapping from $\Omega$ into $\mathcal{M}_{\mathcal{X}}$.
    The distribution of a random measure $\xi$ is the probability measure induced by the probability measure $\PP$.
\end{definition}

%In this sense, $\xi$ is a random variable on the measurable set $\mathcal{M}_{\mathcal{X}}$ whose realisation is a deterministic measure on $\mathcal{X}$.
An equivalent definition of a random measure is obtained through the following result:

\begin{proposition}{\parencite[Proposition 1.1.7]{Baccelli2020}}\label{prop:chap1_random_measure_variable}

    For a mapping $\xi:(\Omega, \mathcal{F}) \to (\mathcal{M}_{\mathcal{X}}, \mathcal{B}(\mathcal{M}_{\mathcal{X}}))$, we define for any $B\in\mathcal{B}_{\mathcal{X}}$ the mapping $\xi(B):(\Omega, \mathcal{F}) \to (\mathcal{X}, \mathcal{B}_{\mathcal{X}})$ as:
    \[\xi(B)(\omega) = (\xi(\omega))(B)\,.\]

    Then, $\xi$ is a random measure if and only if, for all $B\in\mathcal{B}_{\mathcal{X}}$, $\xi(B)$ is measurable.
\end{proposition}
With this result, it means that we can work with a random measure $\xi$ in two ways:
\begin{itemize}
    \item For any $\omega\in\Omega$, a realisation $\xi(\omega)$ is a measure on $\mathcal{X}$.
    \item For any $B\in\mathcal{B}_{\mathcal{X}}$, $\xi(B)$ is a random variable on $\mathcal{X}$. Furthermore, $\{\xi(B)\}_{B\in\mathcal{B}_{\mathcal{X}}}$ is a stochastic process.
\end{itemize}
In practice, as with other random variables we tend to omit the term $\omega$ when working with random measures and using $\xi$ either as a measure or random variable is to be understood by the context.
Another direct result from Proposition~\ref{prop:chap1_random_measure_variable} is that, for any finite sequence $(B_k)_{k=1:K}$ of Borel sets, we can define the random vector:
\[(\xi(B_1), \ldots, \xi(B_K))\,.\]
It turns out that a characterisation of any random measure is given by the distribution of all of these vectors:

\begin{proposition}{\parencite[Corollary 9.2.IV]{DaleyV2}}

    Let $\xi$ be a random measure on $\mathcal{X}$. 
    The finite-dimensional distributions of $\xi$ are the probability distribution of the vectors $(\xi(B_1), \ldots, \xi(B_K))$ for all integers $k\geq 1$ and all sequences of Borel sets $(B_k)_{k=1:K}$.

    The distribution of $\xi$ is fully given by its finite-dimensional distributions.
\end{proposition}
With this result, a way of defining any random measure is by defining its finite-dimensional distributions.
However, not any set of finite-dimensional distributions correspond to those of a random measure, but a set of necessary and sufficient conditions (cf \parencite[Conditions 9.2.V-VI]{DaleyV2}).
Finally, let us introduce the notion of stationarity. 
For any $B\in\mathcal{B}_{\mathcal{X}}$, for any $x\in\mathcal{X}$, we define $B+x$ as the set:
\[B+x = \{b + x \mid b\in B\}\,.\]

\begin{definition}
    A random measure $\xi$ is said to be \emph{stationary} if 
    for any $B\in\mathcal{B}_{\mathcal{X}}$ and for any $x\in\mathcal{X}$, $N(B)$ and $N(B+x)$ follow the same distribution.
\end{definition}

\subsection{Point processes}

Let us now turn to the study of point processes. For this, we need the definition of a counting measure:

\begin{definition}
    A measure $\nu$ on $\mathcal{X}$ is a counting measure if for any $B\in\mathcal{B}_{\mathcal{X}}$, $\nu(B)\in\NN \cup \{+\infty\}$.
    We note $\mathcal{N}_{\mathcal{X}}$ the set of all boundedly finite counting measures in $\mathcal{X}$.
\end{definition}

As done previously, we can equip the space $\mathcal{N}_{\mathcal{X}}$ with a Borel $\sigma$-algebra $\mathcal{B}(\mathcal{N}_{\mathcal{X}})$ generated by the mappings $\nu \to \nu(B)$, for all $B\in\mathcal{B}_{\mathcal{X}}$.

\begin{definition}[Point processes and simple point processes]
    A \emph{point process} $N$ on $\mathcal{X}$ is a measurable mapping from a $(\Omega, \mathcal{F}, \PP)$ into $(\mathcal{N}_{\mathcal{X}}, \mathcal{B}(\mathcal{N}_{\mathcal{X}}))$.
\end{definition}

Intuitively, a point process $N$ is a random measure \parencite[Corollary 1.6.4.]{Baccelli2020} such that, for any $\omega\in\Omega$, the realisation $N(\omega)$ is a counting measure and so in particular all previous results from random measures hold for a point process.
In particular, for any $B\in\mathcal{B}_{\mathcal{X}}$, $N(B)$ will denote the measure of $B$ by $N$, which allows us to introduce the definition of a simple point process:

\begin{definition}
A point process $N$ is \emph{simple} if for any $x\in\mathcal{X}$, $N(\{x\}) = 1$ a.s.
\end{definition}

It is very common in the literature to work uniquely with simple point processes, but before further discussing this, let us exhibit the following result in the theory of point processes:

\begin{theorem}{\parencite[Corollary 6.5]{Last2017}}\label{th:chap1_point_decomposition}

    Let $N$ be a point process on $\mathcal{X}$ and let $\delta_x$ be the Dirac measure on $x$, for any $x\in\mathcal{X}$.
    There exists a random variable $\kappa\in\NN\cup \{+\infty\}$ and a set of random variables $(T_1, T_2, \ldots)$ such that:
    \[N = \sum_{k=1}^{\kappa}{\delta_{T_k}}\,,\quad \text{a.s.}\]  

    We refer to the variables $T_k$ as the \emph{event times} or \emph{points} of process $N$.
\end{theorem}
This theorem reunites the definition of a point process as a random measure with other formalisms of point processes as random points observed in a space $\mathcal{X}$.
A simple point process is then a point process without coinciding points, in other words, for any $i\neq j$, $T_i \neq T_j$ almost surely.
From now on, we will assume that all point processes from now on are simple.

Let us now turn to some particularities of working in a temporal setting. As $\mathcal{X}$ is a well-ordered set, it is practical to order the event times of $N$.
The indexation of the sequence of event times slightly differs whether we work on $\RR_{\geq 0}$ or $\RR$. 
Unlike Theorem~\ref{th:chap1_point_decomposition} may suggest, it is a common adopted convention, when working on the entire real line, that the event times are indexed by $\ZZ$ such that \[\ldots < T_{-2} < T_{-1} < T_{0} \leq 0 < T_1 < T_2 < \ldots\,.\]
This way, positive indices will always denote points \emph{after} the origin of time $t=0$.
Another usual convention is to denote $N(t) = N([0, t])$ the number of points in the interval $[0, t]$ specially used in inference contexts.
This allows also to see $(N(t))_{t\in\mathcal{X}}$ as a right-continuous stochastic process.

\subsection{Integrals and moment measures}

We can define the stochastic integral of a measurable function $f:\mathcal{X}\to \RR_{\geq 0}$ against a point process $N$ with event times $(T_k)_{k\in\ZZ}$ as:
\[\int_{\mathcal{X}}{f(t)\, N(\dd t)} = \sum_{k\in\ZZ}{f(T_k)}\,,\]
which is similar to the Lebesgue-Stieljes.
We can see that the integral defined as so is a random variable and by taking $f=\II_{B}$ for any $B\in\mathcal{B}_{\mathcal{X}}$, we can retrieve the measure of $B$:
\[\int_{\mathcal{X}}{\II_{B}(t)\, N(\dd t)} = \sum_{k\in\ZZ}{\II_{T_k \in B}} = N(B)\,.\]

Let us now define the moment measures of $N$:
\begin{definition}
    Let $N$ be a point process. Whenever it exists, we note $M_k$ the \emph{$k$-th moment measure} of $N$ defined, for any $(B_1,\ldots, B_k)\in\mathcal{B}_{\mathcal{X}}^k$, as:
    \[M_k(B_1, \ldots, B_k) = \EE[N(B_1)\ldots N(B_k)]\,.\]

    In particular, the first moment measure $M_1$ is also known as the \emph{intensity measure} of $N$, also noted $\Lambda$.
\end{definition}
With the intensity measure, we are able to introduce the most classical point process: the Poisson process:

\begin{definition}\label{def:chap1_poisson_process}
    Let $\Lambda$ be an absolutely continuous measure on $\mathcal{X}$ with respect to the Lebesgue measure $\ell$ and let $\lambda:\mathcal{X}\to\RR_{>0}$ be its Radon-Nikodym derivative.

    A point process $N$ is a \emph{Poisson process} with intensity function $\lambda$ if it verifies the following conditions:
    \begin{enumerate}
        \item For any $B\in\mathcal{B}_{\mathcal{X}}$, $N(B)$ follows a Poisson distribution with parameter $\Lambda(B) = \lambda \ell(B)$.
        \item For any integer $K$ and any sequence of disjoint Borel sets $(B_k)_{k=1:K}$, the variables $(N(B_k))_{k=1:K}$ are independent.
    \end{enumerate}

    If $\lambda$ is a constant function, $N$ is called a \emph{homogeneous} Poisson process.
\end{definition}
The Poisson process is sometimes referred to as a process with independent increments because of the second property.
In particular, when the intensity function $\lambda$ is constant, we can further characterise the process by its inter-arrival times:

\begin{theorem}{\parencite[Theorem 7.2]{Last2017}}\label{th:chap1_interarrival_exponential}

    $N$ is a homogeneous Poisson process with intensity $\lambda > 0$ if and only if the inter-arrival times $(T_{k+1} - T_k)_{k\in\ZZ}$ are i.i.d all following an exponential distribution with parameter $\lambda$.
\end{theorem}
%Campbell ??

\subsection{The conditional intensity function}

In the previous subsection, we defined the Poisson processes through their intensity functions, which allows to account for different time-dependent dynamics.
The concept that will allow us to properly introduce the Hawkes process is the conditional intensity function.
For this, let us note $\mathcal{H}_t$ the \emph{history} of a point process $N$ up to the instant $t\in\mathcal{X}$. 
$\mathcal{H}_t$ is the $\sigma$-algebra generated by the event times $T_k$ such that:
\[\mathcal{H}_t = \sigma(\{T_k \mid k\in\ZZ, T_k \leq t\})\,.\]

\begin{definition}\label{def:chap1_conditional_intensity}
    Let $N$ be a simple point process on $\mathcal{X}$, and $(\mathcal{H}_t)_{t\in\mathcal{H}_t}$ the histories of $N$.
    The \emph{conditional intensity function} $\lambda$ of $N$ is defined, for any $t\in\mathcal{X}$, as:
    \begin{equation}\label{eq:chap1_conditional_intensity}
        \lambda(t \mid \mathcal{H}_t) = \lim_{h \to 0}{\frac{\EE[N([t,t+h]) \mid \mathcal{H}_t]}{h}}\,.
    \end{equation}
\end{definition}
Let us remark that by Proposition 7.2.IV in \textcite{DaleyV1}, a point process is entirely determined by its conditional intensity function.
In general, the conditional intensity function $\lambda$ is a random variable for each $t\in\mathcal{X}$ as it is expressed through a conditional expectation.
However, if $\lambda$ is a deterministic function, then it coincides with the intensity function of a Poisson process as given in Definition~\ref{def:chap1_poisson_process}, which justifies keeping the same notation $\lambda$. 

It is a common practice to omit the term $\mathcal{H}_t$ in Equation~\eqref{eq:chap1_conditional_intensity} as a conditional intensity is usually understood as having access to the entire past history (unless it is to avoid ambiguity).
Intuitively $\lambda$ quantifies the instantaneous probability of observing a point on an interval of infinitesimal size $h$.
As $N$ is a simple point process, the expectation in Equation~\eqref{def:chap1_poisson_process} corresponds with $\PP(N([t, t+h]) = 1)$ for a small enough $h$.
Another common interpretation (see \textcite{Hawkes1971}, for an example) of the conditional intensity function for simple point processes is through the following probabilities:
\[
    \begin{cases}
\PP(N([t, t+h]) = 1) = \lambda(t) h + o(h)\\
\PP(N([t, t+h]) = 0) = 1 - \lambda(t) h + o(h)\\
\PP(N([t, t+h]) \geq 2)= o(h)\,.
    \end{cases}
\]
A very formal presentation of the conditional intensity function can be found in \textcite[Chapter 7]{DaleyV1} through the concept of Janossy densities.
In a nutshell, given a number $K$ of observed points in a set $B$, the Janossy densities describe the probability distribution of points $(T_k)_{k=1:K}$ inside $B$.

\begin{definition}
    Let $N$ be a simple point process and $\lambda$ its conditional intensity function.
    The \emph{compensator} $\Lambda$ of $N$ is the random measure defined, for any $B\in\mathcal{B}_{\mathcal{X}}$ as:
    \[\Lambda(B) = \int_{B}{\lambda(t)\,\dd t}\,.\]

    In particular, $\Lambda$ is the first-order moment measure of $N$.
    If $N$ is stationary, then $\Lambda$ is a constant multiple of the Lebesgue measure $\ell$.
\end{definition}
Again, the concept of compensator coincides with the intensity measure in Definition~\ref{def:chap1_poisson_process} whenever $\lambda$ is deterministic.
Similarly to the notation of point processes, we note $\Lambda(t) = \Lambda([0,t])$ for any $t\in\mathcal{X}$.
The compensator is a highly studied quantity for point processes defined through conditional intensity functions.
An important result concerning $\Lambda$ is the Time Change theorem:

\begin{theorem}{\parencite[Theorem 7.4.IV]{DaleyV1}}

    Let $N$ be a point process with conditional intensity function $\lambda$ and compensator $\Lambda$.
    Let us assume that $\Lambda:t\to \Lambda(t)$ is a continuous, monotone and such that $\lim_{t\to+\infty}\Lambda(t) = +\infty$ a.s.
    Then, the sequence $(T_k)_{k\in\ZZ}$ are the event times of $N$ if and only if $(\Lambda(T_k))_{k\in\ZZ}$ are the event times of a homogeneous Poisson process with intensity $\lambda=1$.
\end{theorem}
It is then possible to rescale the event times of any observed point process $N$ in order to obtain a realisation of a homogeneous Poisson process.
This is an very useful result in order to establish goodness-of-fit procedures for point processes when an estimation $\hat \Lambda$ of $\Lambda$ is available.
For example, by transforming the observed event times $(T_k)_k$ with $\hat \Lambda$, we can then test whether the inter-arrival times $(\hat \Lambda(T_{k+1}) - \hat \Lambda(T_k))_k$ are exponentially distributed (see Theorem~\ref{th:chap1_interarrival_exponential}).

Lastly, we conclude this section by introducing the expression of the likelihood:

\begin{proposition}{\parencite[Theorem 7.2.III]{DaleyV1}}

    Let $N$ be a point process with conditional intensity function $\lambda$.
    Let $(T_k)_{k=1:N(T)}$ be the realisation of $N$ in the interval $[0, T]$.
    
    Then the likelihood $L_T$ of $N$ reads:
    \begin{equation}\label{eq:chap1_likelihood}
        L_T = \left(\prod_{k=1}^{N(T)}{\lambda(T_k^-)}\right)\mathrm{e}^{-\Lambda(T)}\,,
    \end{equation}
    where $\lambda(T_k^-) = \lim_{t\to T_k^-}(\lambda(t))$.

    The log-likelihood of $N$ is:
    \[\ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,.\]
\end{proposition}
The likelihood can be introduced by means of the Janossy densities.
Let us note that, in the case of point processes on the entire real line $\RR$, the conditional intensity function necessitates to know the location of all points in the past before $T$ in order to compute the likelihood, which is usually unavailable.
In practice, it is often assumed that no points occured in $(-\infty, 0)$ and so an adapted version of $\lambda$ is used in Equation~\ref{eq:chap1_likelihood} (see \textcite{Ogata1978}).

\section{Hawkes process}\label{sec:chap1_hawkes_process}

\subsection{The self-exciting Hawkes process}

The Hawkes process, as introduced in \textcite{Hawkes1971}, is defined as a point process in $\RR$ as follows:

\begin{definition}\label{def:chap1_hawkes_process}
    Let $\mu>0$ and $h:\RR_{\geq 0}\to\RR_{\geq 0}$ be a measurable function such that \[\|h\|_1 = \int_{0}^{+\infty}{h(t)\,\dd t} < 1\,.\]

    A \emph{Hawkes process} $N$ is a point process defined by the conditional intensity function:
    \begin{equation}\label{eq:chap1_hawkes_intensity}
        \lambda(t) = \mu + \int_{-\infty}^{t}{h(t-s)\,N(\dd s)}\,.
    \end{equation}
    $\mu$ is known as the \emph{baseline intensity} and $h$ as the \emph{interaction} or \emph{kernel function}.
\end{definition}
This process was initially referred to as a self-exciting point process due to the integral in Equation~\eqref{eq:chap1_hawkes_intensity} that represents the contribution of all past points up to time $t$ to the intensity function $\lambda$. In order to define a Hawkes process in $\RR_{\geq 0}$, it suffices to replace the lower bound in the integral by $0$.
Let us recall that:
\[\int_{-\infty}^{t}{h(t-s)\,N(\dd s)} = \sum_{T_k \leq t}{h(t - T_k)}\,,\]
and so each event time $T_k$ increases the baseline intensity by an additive factor of $h(t - T_k)$, hence the self-excitation effect.
%Image with simulation and say that it is done with method from github

The condition \[\int_{0}^{+\infty}{h(t)\,\dd t} < 1\,,\] for the interaction function ensures that $N$ is boundedly finite a.s. and so that $N$ is a point process.
Another result of this condition is that $\lim_{t\to+\infty}h(t) = 0$, meaning that the effect of any point $T_k$ dissipates the further they are in the past.

Another implication of this condition is that a Hawkes process defined in $\RR$ is a stationary point process which allows to establish the following result:

\begin{proposition}
    Let $N$ be a stationary Hawkes process.
    Then the average intensity of $N$ reads:
    \[\EE[\lambda(t)] = \frac{\mu}{1-\|h\|_1}\,.\]
\end{proposition}
The stationarity of process $N$ is verified for processes only in $\RR$ and so this result does not hold for a process in $\RR_{\geq 0}$.
On the one hand, it is often more practical for theoretical reasons to work in $\RR$, as stationarity tends to facilitate establishing certain results (see \textcite{Hawkes1971} for example in the context of spectral theory).
On the other hand, a process in $\RR_{\geq 0}$ is often preferred for application purposes, as it is unrealistic to suppose that the practitioner has access to an infinite number of points in the past before $t=0$.

%This is a result of stationarity and the Campbell formula for point processes \parencite[Proposition 2.7]{Last2017}. 

\subsection{The multivariate Hawkes process}

The multivariate version of a self-exciting Hawkes process was simultaneously introduced in \textcite{Hawkes1971} as follows: 

\begin{definition}\label{def:chap1_multivariate_hawkes}
    We define a multivariate Hawkes process $N = (N_1, \ldots, N_d)$ of dimension $d$ is defined by $d$ point processes $(N_i)_{i=1:d}$.
    For each integer $i$, we note $T_k^i$ the event times of process $N_i$ and its conditional intensity function $\lambda^i$ reads:
    \[\lambda^i(t) = \mu_i + \sum_{j=1}^{d}\int_{-\infty}^{t}{h_{ij}(t-s)}\,N^j(\dd s)\,.\]
    For any integer $i$, $\mu_i>0$ is the baseline intensity of $N_i$ and $h_{ij}\colon\RR_{\geq 0}\to \RR_{\geq 0}$ is a measurable function.
\end{definition}
For a multivariate Hawkes process, each intensity function $\lambda^i$ is influenced by every point $T_k^j$ of process $N_j$, for all integers $j$.
Function $h_{ij}$ represents the influence of a point from $N_j$ to process $N_i$. We define the matrix $S = (\|h_{ij}\|_1)_{1 \geq i,j \geq d}$ and a condition for all $N^i$ to be proper point processes is to control the spectral radius $\rho(S) < 1$ \parencite{Bacry2015}.
This condition ensures again the stationarity of all processes when defined in $\RR$.

When $d=1$, we retrieve the original expression of a Hawkes process from Defintion~\ref{def:chap1_hawkes_process} and so we talk about an univariate Hawkes process. 
Defining a multivariate Hawkes process as a vector is the more common formulation for any kind of point process, but it is sometimes practical to consider process $N$ as the superposition of all subprocesses $N^i$.
$N$ is then characterised by the ordered union of all event times $(T_k^i)_{k\in\ZZ}$ for all integers $i$, forming a single point process in $\RR$ with event times $(T_{(k)})$ and conditional intensity function:

\[\lambda(t) = \sum_{i=1}^{d}{\lambda^i(t)}\,.\]
This perspective allows to extend any result from general point process theory to a multivariate process $N$, including inference methods.


\section{Inference for Hawkes processes}\label{sec:chap1_inference}

Estimation for Hawkes processes consists in estimating both the baseline intensity $\mu$ and the interaction function $h$ for a realisation of $N$ in a window $[0,T]$.
A common optimisation procedure is the maximisation of the log-likelihood:
\[\ell_T = \sum_{k=1}^{N(T)}{\log(\lambda(T_k^-))} - \Lambda(T)\,,\]
as shown in \textcite{Ozaki1979} and a multivariate version is presented in \textcite{Embrechts2011, Guo2018} with good mathematical properties including consistency and asymptotic normality \parencite{Clinet2017}, mainly developed in parametric settings.
We provide an insight of this method in Section~\ref{sec:chap1_exponential_MLE} for an exponential parametrisation of $h$.
Other methods implemented in parametric settings are the method of moments \parencite{DaFonseca2013}, through spectral analysis \parencite{Adamopoulos1976} or by leveraging the branching structure of Hawkes processes \parencite{Veen2008}.

Inference procedures in non-parametric settings tend to be based in minimisation a least-squares contrast defined, for an estimator $\hat \lambda$ of the real intensity $\lambda$, as:
\[\|\hat \lambda - \lambda\|_2^2 = \int_{0}^{T}{(\hat\lambda(t) - \lambda(t))^2\,\dd t}\,,\]
usually by approximating $h$ through histograms \parencite{Lemonnier2014, Reynaud2014} or by using autoregressive models \parencite{Kirchner2017}. Other methods include solving Wiener-Hopf equations \parencite{Bacry2016}, by optimising a penalised log-likelihood through an EM algorithm \parencite{Lewis2011} or by fitting second and third-order cumulants \parencite{Achab2016}. 

\subsection{MLE for Hawkes process with exponential kernel}\label{sec:chap1_exponential_MLE}

Let us illustrate the implementation of the maximum likelihood estimation method for univariate Hawkes processes.
Let $N$ be a Hawkes process in $\RR_{\geq 0}$ and we assume that the function $h$ is parametrised by an exponential distribution such that:
\[h(t) = \alpha\mathrm{e}^{-\beta t}\,, \quad \text{for $t\geq 0$,}\]
with $\alpha >0$ and $\beta>0$.
The existence condition in Definition~\ref{def:chap1_hawkes_process} reads:
\[\|h\|_1 = \frac{\alpha}{\beta} < 1\,,\]
and so we assume that $\alpha < \beta$. 
By defining the following parametric model:
\[\mathcal{P} = \left\{
    \lambda_\theta \mid \theta = (\mu, \alpha, \beta)\in\RR_{\geq 0}^3, \alpha < \beta
\right\}\,,\]
the log-likelihood \eqref{eq:chap1_likelihood} becomes a function of parameter $\theta$:
\[
    \ell_T(\theta) = \sum_{k=1}^{N(T)}{\log(\lambda_\theta(T_k^-))} - \Lambda_\theta(T)\,,
\]
with $\Lambda_\theta$ the compensator of $\lambda_\theta$.

The choice of the exponential kernel function for $N$ implies that the intensity $\lambda$ is Markovian in the sense that in each interval $[T_k,T_{k+1})$ the expression is solely dependant on the value of $\lambda(T_k)$.
For any integer $k\geq 1$ and any $t\in[T_k,T_{k+1})$, the intensity reads:
\begin{align}
    \lambda(t) = \mu + \int_{0}^{+\infty}{\alpha \mathrm{e}^{-\beta(t-s)}\,N(\dd s)} &= \mu + \sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(t-T_j)}}\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(T_k-T_j)}}\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\left(\mu + \sum_{j=1}^{k}{\alpha \mathrm{e}^{-\beta(T_k-T_j)}} - \mu\right)\nonumber\\
    &=\mu + \mathrm{e}^{-\beta(t - T_k)}\left(\lambda(T_k) - \mu\right)\label{eq:chap1_recursive_intensity}\,.
\end{align}
We can then easily integrate $\lambda$ in $[T_k,T_{k+1})$:
\begin{align*}
    \int_{T_k}^{T_{k+1}}{\lambda(t)\,\dd t} &= \mu(T_{k+1} - T_k) + (\lambda(T_k) - \mu) \int_{T_k}^{T_{k+1}}{\mathrm{e}^{-\beta(t - T_k)}\,\dd t}\\
    &= \mu(T_{k+1} - T_k) + (\lambda(T_k) - \mu)\beta^{-1}(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})
\end{align*}

Then, for any interval $[0, T]$, the compensator $\Lambda$ can be computed piecewise:
\begin{align*}
    \Lambda(T) &= \int_{0}^{T}{\lambda(t)\,\dd t}\\
    &= \int_{0}^{T_1}{\mu\,\dd t} + \sum_{k=1}^{N(T)-1}\int_{T_k}^{T_{k+1}}{\lambda(t)\,\dd t} + \int_{T_{N(T)}}^{T}{\lambda(t)\,\dd t}\\
    &= \mu T + \beta^{-1}\left(\sum_{k=1}^{N(T)-1}{(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})} + (\lambda(T_{N(T)}) - \mu)(1 - \mathrm{e}^{-\beta(T - T_k)})\right)\,.
\end{align*}
The importance of this expression is that the terms $\lambda(T_k)$ (and $\lambda(T_k^-)$) can be computed recursively by Equation~\ref{eq:chap1_recursive_intensity} and so $\Lambda$ has a computational complexity of $O(N(T))$. 
The log-likelihood also has a complexity of $O(N(T))$ and can be efficiently computed as described in Algorithm~\ref{alg:chap_1_loglikelihood}:

\begin{algorithm}[ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $\alpha$, $\beta$, time horizon $T$ and sequence of event times $(T_k)_{k=1:N(T)}$\;
     \textbf{\underline{Initialization}} Initialize $\ell_T = \log(\mu) - \mu T$, $\lambda(T_k) = \mu + \alpha$ and $T_{k} = T_1$\;
     \For{k > 2}{
        Compute $\lambda(T_{k+1}^-) = \mu + (\lambda(T_k) - \mu)\mathrm{e}^{-\beta(T_{k+1} - T_k)}$\;
        Update $\ell_T = \ell_T + \log(\lambda(T_{k+1}^-) ) - \beta^{-1}(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T_{k+1} - T_k)})$\;
        Update $\lambda(T_k) = \lambda(T_{k+1}^-) + \alpha$\;
        Update $T_k = T_{k+1}$\;
        }
    Update $\ell_T = \ell_T - \beta^{-1}(\lambda(T_k) - \mu)(1 - \mathrm{e}^{-\beta(T - T_k)})$\;
     \Return Log-likelihood $\ell_T$
     \caption{Computation of $\ell_T$}
     \label{alg:chap_1_loglikelihood}
\end{algorithm}

In practice, we obtain an estimation $\hat \theta$ of a parameter $\theta = (\mu, \alpha, \beta)$ by maximising the log-likelihood.


\section{Simulation}\label{sec:chap1_simulation}

\subsection{Ogata's thinning simulation}

The most classical method to simulate point processes with an intensity function $\lambda$ is obtained through a rejection algorithm. An important condition to implement this method is to for the intensity function to be upper-bounded by a constant $\lambda^\star$.
We may then simulate $N$ by first simulating a homogeneous Poisson process with intensity $\lambda^\star$ and then thinning each point with probability $\lambda(t) / \lambda^\star$.

In general, it is not possible to find an upper bound for the intensity of a Hawkes processe. Additionally, the intensity function is dependant on each simulated point so each time a point appears, it has to be updated. In order to account for these particularities of a Hawkes process, one of the most used methods is Ogata's thinning algorithm \parencite{Ogata1981}.
To simulate the points of a process $N$ in a window of time $[0,T]$ (with the convention that $T_0 = 0$), we follow the following paradigm:

\begin{enumerate}
\item Assume that event time $T_k < T$ has been simulated.
\item Estimate an upper bound $\lambda^\star$ of $\lambda$ on the interval $[T_k, T]$.
\item Simulate a candidate point $t_{cand}$ according to an exponential distribution with mean $1 / \lambda^\star$.
\item Compute the intensity $\lambda(t_{cand})$
\item Accept the candidate with probability $\lambda(t_{cand}) / \lambda^\star$.
\end{enumerate}
This algorithm generalises the case where a global upper bound is known by allowing for upper bounds to instead be local.

For the simulation of a Hawkes process, we recall that the interaction function $h$ is such that:
\[\|h\|_1 < 1\,,\]
so in particular it is upper-bounded and attains its upper bound noted $\|h\|_{\infty}$. We can then sequentially determine an upper bound. Without any other constraints on $h$, for a set of simulated event times $(T_1, \ldots, T_k)$, an upper bound for $\lambda$ on the interval $[T_k, +\infty]$ (assuming no other points) is given by:
\[\lambda^\star = \mu + k\|h\|_{\infty}\,.\]
This is clearly a very rough bound and can be easily improved under certain conditions, for example if $h$ is a decreasing function. In this case, then $\lambda$ is piecewise decrasing and so the upper bound becomes:
\[\lambda^\star = \lambda(T_k) + h(0)\,.\]
Choosing a smaller upper-bound improves the simulation time by reducing the overall number of candidates and rejections.

Algorithm~\ref{alg:chap1_ogata_simulation} displays the adaptation of Ogata's thinning algorithm to Hawkes processes for a monotone interaction function.

\begin{algorithm}[!ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $h$ a monotone function, and a stopping criteria (end-time $T$ or maximal number of jumps $N_{max}$)\;
     \textbf{\underline{Initialization}} Initialize $\lambda_k =\mu$, $t_k=0$\ and list of times $\mathcal{T} = \emptyset$\;
     \While{\textnormal{Stopping criteria not fulfilled}}{
     Set $\lambda^\star = \lambda_k$\;
     Generate candidate time $t_{cand} = t_k - \frac{\log(U_1)}{\lambda^\star}$, $U_1\sim U([0,1])$\;
     Compute intensity $\lambda_k = \lambda(t_{cand})$ using sequence of times $\mathcal{T}$\;
     Sample $U_1\sim U([0,1])$\;
     \If{$U_1 \leq \frac{\lambda_k}{\lambda^\star}$}{
            Add $t_{cand}$ to sequence of times $\mathcal{T}$\;
            Update $\lambda_k = \lambda_k + h(0)$\;
         }
     Set $t_k = t_{cand}$\;
     }
     \Return the sequence of jumps $\mathcal{T}$.
     \caption{Thinning algorithm for monotone self-exciting Hawkes process.}
     \label{alg:chap1_ogata_simulation}
\end{algorithm}

\subsection{Simulation through branching theory}

Another simulation algorithm is based on what is called the branching structure of a Hawkes process.
By Definition~\ref{def:chap1_hawkes_process}, the Hawkes process can be seen as a branching Poisson process as described below:
\begin{enumerate}
    \item Let $N_c$ be a homogeneous Poisson process with intensity $\mu$. All event times $(T_k^c)_{k\in\ZZ}$ are known as parents.
    \item Each parent $T_k^c$ generates a subsidiary process of descendants $C_k$ of event times as follows:
    \begin{itemize}
        \item A first generation $C_{k,1}$ is generated as an inhomogenous Poisson process with intensity $h(\cdot - T_k^c)$.
        \item Each child point $t$ in $C_{k,1}$ generates a new generation $C_{k,2}$ inhomogenous Poisson process with intensity $h(\cdot - t)$.
        \item This is repeated for each generated point until no new points are born. 
        $C_k$ is formed by the union of all points in each subprocess $C_{k, j}$
    \end{itemize}
    \item The process $N$ composed of the ordered union of all parents $(T_k^c)_k$ and all points in every subprocess $(C_k)_{k}$ is a Hawkes process.
\end{enumerate}
The branching Poisson processes were introduced in \textcite{Lewis1969} and allows to leverage the theory of branching processes to study Hawkes processes.
In particular, this procedure can be used to simulate a Hawkes process $N$ as presented in Algorithm~\ref{alg:chap1_branching_simulation}:

\begin{algorithm}[ht]
    \SetAlgoLined
     \textbf{Input} Parameters $\mu$, $h$ a positive function, and an end-time $T$\;
     \textbf{\underline{Initialization}} Initialize list of times $\mathcal{T}$, $t_k=0$ and auxiliary empty list $L_{aux}$\;
     Generate the number of parents $N_0$ according to a Poisson distribution with parameter $\mu T$\;
     Generate parent event times $T_k^c$ as $N_0$ independent and uniformly distributed points in $[0, T]$\;
     Update $L_{aux} = C_{k,j}$\;
     Add all points $(T_k^c)$ to $\mathcal{T}$\;
     \While{$L_{aux}$ \textnormal{is not empty}}{
        \For{t in $L_{aux}$}{
            Generate a number of children $\|h\|_1$\;
            Generate the children times distributed according to the probability density function $h(\cdot - t)/\|h\|_1$.
            Add all points inside the simulation window $[0, T]$ to $L_{aux}$ and $\mathcal{T}$\;
        }    
     }
     \Return Ordered sequence of jumps $\mathcal{T}$
     \caption{Branching simulation algorithm for self-exciting Hawkes process}
     \label{alg:chap1_branching_simulation}
    \end{algorithm}
The fact that such an algorithm will end, in other words that each subsidiaty process will end up by not generating any point, is a direct consequence of the condition $\|h\|_1 < 1$.
This is a result of Galton-Watson process theory, as each point tends to generate on average less than a children, the branches will "die out" eventually.

This algorithm presents some advantages when compared to Ogata's procedure.
First, it does not require to compute an upper-bound for the intensity function, which as seen previously, is an important step in Algorithm~\ref{alg:chap1_ogata_simulation}.
Second, this procedure does not have a rejection step and there is no need to compute the value $\lambda$ each time that a point is simulated, which can greatly reduce the overall computation time.
Overall, the only constraint on $h$ imposed by Algorithm~\ref{alg:chap1_branching_simulation} is to be able to simulate according to the probability density function $h(\cdot - t)/\|h\|_1$, unlike the thinning algorithm whose simulation time is greatly dependant in the choide of $h$.